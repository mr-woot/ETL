2021-11-25 11:31:52 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:31:58 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:31:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:31:58 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:31:58 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:31:58 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:31:58 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:31:58 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:31:58 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:32:03 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 53915.
2021-11-25 11:32:04 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:32:04 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:32:04 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:32:04 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:32:04 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-70dd16d6-92a1-4320-9da7-1864af9c84d4
2021-11-25 11:32:04 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:32:04 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:32:04 INFO  log:192 - Logging initialized @11915ms
2021-11-25 11:32:04 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:32:04 INFO  Server:419 - Started @11965ms
2021-11-25 11:32:04 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:32:04 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 11:32:04 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:32:04 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53916.
2021-11-25 11:32:04 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:53916
2021-11-25 11:32:04 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:32:04 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 53916, None)
2021-11-25 11:32:04 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:53916 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 53916, None)
2021-11-25 11:32:04 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 53916, None)
2021-11-25 11:32:04 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 53916, None)
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:32:04 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60baef24{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad5923a{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4463d9d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:32:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13d186db{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:32:05 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:32:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:32:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:32:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:32:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:32:09 INFO  CodeGenerator:54 - Code generated in 385.315625 ms
2021-11-25 11:32:09 INFO  CodeGenerator:54 - Code generated in 25.251666 ms
2021-11-25 11:32:09 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:32:10 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:32:10 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:53916 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:32:10 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:60
2021-11-25 11:32:10 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:32:10 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:60
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:60) with 1 output partitions
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:60)
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60), which has no missing parents
2021-11-25 11:32:10 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 11:32:10 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:32:10 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:53916 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:32:10 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:32:10 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:32:10 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:32:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:32:10 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:32:10 INFO  CodeGenerator:54 - Code generated in 151.581125 ms
2021-11-25 11:32:10 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 11:32:10 INFO  CodeGenerator:54 - Code generated in 65.919041 ms
2021-11-25 11:32:11 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2237 bytes result sent to driver
2021-11-25 11:32:11 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 553 ms on localhost (executor driver) (1/1)
2021-11-25 11:32:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:32:11 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:60) finished in 0.758 s
2021-11-25 11:32:11 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:60, took 0.803431 s
2021-11-25 11:32:11 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:32:11 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:32:11 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 11:32:11 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:32:11 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:32:11 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:32:11 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:32:11 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:32:11 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:32:11 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:32:11 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-c0c95134-4c21-48d2-bc25-06cfc6c4fa11
2021-11-25 11:35:22 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:35:28 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:35:28 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:35:28 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:35:28 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:35:28 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:35:28 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:35:28 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:35:28 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:35:34 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54511.
2021-11-25 11:35:34 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:35:34 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:35:34 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:35:34 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:35:34 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-47ff29d7-42f5-4c06-910c-8dd818603b96
2021-11-25 11:35:34 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:35:34 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:35:34 INFO  log:192 - Logging initialized @12319ms
2021-11-25 11:35:34 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:35:34 INFO  Server:419 - Started @12375ms
2021-11-25 11:35:34 INFO  AbstractConnector:278 - Started ServerConnector@6b1dbbd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:35:34 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a8ab068{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a7e2d9d{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f19b8b3{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/static,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64da2a7{/,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b9d6699{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:35:34 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:35:34 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:35:34 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54512.
2021-11-25 11:35:34 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:54512
2021-11-25 11:35:34 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:35:34 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 54512, None)
2021-11-25 11:35:34 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:54512 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 54512, None)
2021-11-25 11:35:34 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 54512, None)
2021-11-25 11:35:34 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 54512, None)
2021-11-25 11:35:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5767b2af{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:35:35 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:35:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f012914{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@732bb66d{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5395ea39{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:35:35 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:35:38 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:35:38 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:35:38 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:35:38 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:35:39 INFO  CodeGenerator:54 - Code generated in 498.534042 ms
2021-11-25 11:35:39 INFO  CodeGenerator:54 - Code generated in 44.07225 ms
2021-11-25 11:35:40 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:35:40 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:35:40 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:54512 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:35:40 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:60
2021-11-25 11:35:40 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:35:40 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:60
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:60) with 1 output partitions
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:60)
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60), which has no missing parents
2021-11-25 11:35:40 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:35:40 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:35:40 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:54512 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:35:40 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:35:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:35:40 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:35:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:35:40 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:35:41 INFO  CodeGenerator:54 - Code generated in 236.051125 ms
2021-11-25 11:35:41 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 11:35:41 INFO  CodeGenerator:54 - Code generated in 39.022959 ms
2021-11-25 11:35:41 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2455 bytes result sent to driver
2021-11-25 11:35:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 702 ms on localhost (executor driver) (1/1)
2021-11-25 11:35:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:35:41 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:60) finished in 0.962 s
2021-11-25 11:35:41 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:60, took 1.020882 s
2021-11-25 11:35:41 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:35:41 INFO  AbstractConnector:318 - Stopped Spark@6b1dbbd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:35:42 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:35:42 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:35:42 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:35:42 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:35:42 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:35:42 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:35:42 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:35:42 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:35:42 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-8e6814bb-2920-4ec5-991d-c34e1aaaa1ed
2021-11-25 11:36:25 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:36:30 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:36:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:36:31 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:36:31 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:36:31 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:36:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:36:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:36:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:36:36 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54611.
2021-11-25 11:36:36 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:36:36 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:36:36 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:36:36 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:36:36 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-35eeeb52-2829-4581-b17d-700478a311c5
2021-11-25 11:36:36 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:36:36 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:36:36 INFO  log:192 - Logging initialized @12025ms
2021-11-25 11:36:36 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:36:36 INFO  Server:419 - Started @12073ms
2021-11-25 11:36:36 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:36:36 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:36:36 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:36:37 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:36:37 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54612.
2021-11-25 11:36:37 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:54612
2021-11-25 11:36:37 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:36:37 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 54612, None)
2021-11-25 11:36:37 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:54612 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 54612, None)
2021-11-25 11:36:37 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 54612, None)
2021-11-25 11:36:37 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 54612, None)
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:37 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:36:37 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:36:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:36:38 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:36:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:36:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:36:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:36:41 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:36:42 INFO  CodeGenerator:54 - Code generated in 397.640584 ms
2021-11-25 11:36:43 INFO  CodeGenerator:54 - Code generated in 36.624208 ms
2021-11-25 11:36:43 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:36:43 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:36:43 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:54612 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:36:43 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:60
2021-11-25 11:36:43 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:36:43 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:60
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:60) with 1 output partitions
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:60)
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60), which has no missing parents
2021-11-25 11:36:43 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:36:43 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:36:43 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:54612 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:36:43 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:36:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:60) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:36:43 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:36:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:36:43 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:36:43 INFO  CodeGenerator:54 - Code generated in 166.794125 ms
2021-11-25 11:36:43 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 11:36:44 INFO  CodeGenerator:54 - Code generated in 50.044375 ms
2021-11-25 11:36:44 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2455 bytes result sent to driver
2021-11-25 11:36:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 544 ms on localhost (executor driver) (1/1)
2021-11-25 11:36:44 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:36:44 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:60) finished in 0.748 s
2021-11-25 11:36:44 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:60, took 0.790840 s
2021-11-25 11:36:44 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:36:44 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:36:44 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:36:44 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:36:44 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:36:44 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:36:44 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:36:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:36:44 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:36:44 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:36:44 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-6308bd47-84aa-45e9-a509-b012488442f2
2021-11-25 11:37:29 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:37:35 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:37:35 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:37:35 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:37:35 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:37:35 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:37:35 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:37:35 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:37:35 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:37:40 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54702.
2021-11-25 11:37:40 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:37:41 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:37:41 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:37:41 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:37:41 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-2b0c90f7-bb22-4c44-9590-b0ef966bf561
2021-11-25 11:37:41 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:37:41 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:37:41 INFO  log:192 - Logging initialized @11955ms
2021-11-25 11:37:41 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:37:41 INFO  Server:419 - Started @12002ms
2021-11-25 11:37:41 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:37:41 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:37:41 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:37:41 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54703.
2021-11-25 11:37:41 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:54703
2021-11-25 11:37:41 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:37:41 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 54703, None)
2021-11-25 11:37:41 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:54703 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 54703, None)
2021-11-25 11:37:41 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 54703, None)
2021-11-25 11:37:41 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 54703, None)
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:37:41 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:37:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:37:42 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:37:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:37:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:37:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:37:45 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:37:45 INFO  CodeGenerator:54 - Code generated in 333.185667 ms
2021-11-25 11:37:46 INFO  CodeGenerator:54 - Code generated in 29.02875 ms
2021-11-25 11:37:46 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:37:46 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:37:46 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:54703 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:37:46 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:59
2021-11-25 11:37:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:37:46 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:59
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:59) with 1 output partitions
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:59)
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:59), which has no missing parents
2021-11-25 11:37:46 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:37:46 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:37:46 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:54703 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:37:46 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:37:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:59) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:37:46 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:37:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:37:46 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:37:47 INFO  CodeGenerator:54 - Code generated in 169.19025 ms
2021-11-25 11:37:47 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 11:37:47 INFO  CodeGenerator:54 - Code generated in 38.542583 ms
2021-11-25 11:37:47 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2455 bytes result sent to driver
2021-11-25 11:37:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 553 ms on localhost (executor driver) (1/1)
2021-11-25 11:37:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:37:47 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:59) finished in 0.754 s
2021-11-25 11:37:47 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:59, took 0.796291 s
2021-11-25 11:37:47 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:37:47 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:37:47 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:37:47 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:37:47 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:37:47 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:37:47 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:37:47 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:37:47 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:37:47 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:37:47 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-fe344b56-ebc8-49c7-9dc8-446088340f1c
2021-11-25 11:40:49 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:40:54 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:40:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:40:55 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:40:55 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:40:55 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:40:55 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:40:55 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:40:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:41:00 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 54992.
2021-11-25 11:41:00 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:41:00 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:41:00 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:41:00 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:41:00 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-3d33b743-1215-43f6-997a-69bb30593664
2021-11-25 11:41:00 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:41:00 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:41:00 INFO  log:192 - Logging initialized @12129ms
2021-11-25 11:41:00 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:41:01 INFO  Server:419 - Started @12187ms
2021-11-25 11:41:01 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:41:01 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:41:01 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:41:01 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54993.
2021-11-25 11:41:01 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:54993
2021-11-25 11:41:01 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:41:01 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 54993, None)
2021-11-25 11:41:01 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:54993 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 54993, None)
2021-11-25 11:41:01 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 54993, None)
2021-11-25 11:41:01 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 54993, None)
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:41:01 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:41:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:41:02 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:41:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:41:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:41:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:41:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:41:04 INFO  CodeGenerator:54 - Code generated in 201.053958 ms
2021-11-25 11:41:05 INFO  CodeGenerator:54 - Code generated in 33.322833 ms
2021-11-25 11:41:05 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:41:05 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:41:05 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:54993 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:41:05 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:57
2021-11-25 11:41:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:41:05 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:57
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:57) with 1 output partitions
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:57)
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:57), which has no missing parents
2021-11-25 11:41:05 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.0 MB)
2021-11-25 11:41:05 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.0 MB)
2021-11-25 11:41:05 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:54993 (size: 3.7 KB, free: 912.3 MB)
2021-11-25 11:41:05 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:57) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:41:05 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:41:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:41:05 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:41:05 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 11:41:05 INFO  CodeGenerator:54 - Code generated in 32.455541 ms
2021-11-25 11:41:05 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2337 bytes result sent to driver
2021-11-25 11:41:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 284 ms on localhost (executor driver) (1/1)
2021-11-25 11:41:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:41:05 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:57) finished in 0.456 s
2021-11-25 11:41:05 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:57, took 0.495680 s
2021-11-25 11:41:05 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:41:05 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:41:05 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:41:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:41:05 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:41:05 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:41:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:41:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:41:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:41:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:41:05 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-43be182e-4fc2-40e1-b13f-ff23a76ac769
2021-11-25 11:48:57 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:49:02 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:49:03 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:49:03 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:49:03 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:49:03 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:49:03 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:49:03 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:49:03 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:49:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55770.
2021-11-25 11:49:08 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:49:08 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:49:08 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:49:08 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:49:08 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-d852cd1c-25d3-4bde-934a-9d84d1f54191
2021-11-25 11:49:08 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:49:08 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:49:08 INFO  log:192 - Logging initialized @12089ms
2021-11-25 11:49:08 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:49:08 INFO  Server:419 - Started @12149ms
2021-11-25 11:49:08 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:49:08 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:49:08 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:49:09 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:49:09 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55771.
2021-11-25 11:49:09 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:55771
2021-11-25 11:49:09 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:49:09 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 55771, None)
2021-11-25 11:49:09 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:55771 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 55771, None)
2021-11-25 11:49:09 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 55771, None)
2021-11-25 11:49:09 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 55771, None)
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:09 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:49:09 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:49:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:49:10 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:49:13 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:49:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:49:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:49:13 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:49:13 INFO  CodeGenerator:54 - Code generated in 362.588833 ms
2021-11-25 11:49:14 INFO  CodeGenerator:54 - Code generated in 35.946459 ms
2021-11-25 11:49:14 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:49:14 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:49:14 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:55771 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:49:14 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:61
2021-11-25 11:49:14 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:49:14 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:61
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:61) with 1 output partitions
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:61)
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:61), which has no missing parents
2021-11-25 11:49:14 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:49:14 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:49:14 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:55771 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:49:14 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:49:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:61) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:49:14 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:49:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:49:14 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:49:15 INFO  CodeGenerator:54 - Code generated in 157.401083 ms
2021-11-25 11:49:15 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:49:15 INFO  CodeGenerator:54 - Code generated in 49.869542 ms
2021-11-25 11:49:15 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 11:49:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 563 ms on localhost (executor driver) (1/1)
2021-11-25 11:49:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:49:15 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:61) finished in 0.791 s
2021-11-25 11:49:15 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:61, took 0.836222 s
2021-11-25 11:49:15 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:49:16 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:49:16 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:49:16 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:49:16 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:49:16 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:49:16 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:49:16 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:49:16 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:49:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:49:16 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-79abd6bb-064f-4eb2-b62c-2fba3a0357c4
2021-11-25 11:50:46 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:50:51 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:50:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:50:52 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:50:52 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:50:52 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:50:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:50:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:50:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:50:57 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 55926.
2021-11-25 11:50:57 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:50:57 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:50:57 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:50:57 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:50:57 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-e03d10b7-46d8-4800-83b7-156a5fbcd3ed
2021-11-25 11:50:57 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:50:57 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:50:57 INFO  log:192 - Logging initialized @12288ms
2021-11-25 11:50:57 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:50:57 INFO  Server:419 - Started @12335ms
2021-11-25 11:50:57 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:50:57 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:50:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:50:58 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:50:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55927.
2021-11-25 11:50:58 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:55927
2021-11-25 11:50:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:50:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 55927, None)
2021-11-25 11:50:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:55927 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 55927, None)
2021-11-25 11:50:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 55927, None)
2021-11-25 11:50:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 55927, None)
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:50:58 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:50:58 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:50:59 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:51:02 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:51:02 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:51:02 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:51:02 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:51:02 INFO  CodeGenerator:54 - Code generated in 332.456625 ms
2021-11-25 11:51:02 INFO  CodeGenerator:54 - Code generated in 37.751625 ms
2021-11-25 11:51:02 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:51:03 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:51:03 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:55927 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:51:03 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:62
2021-11-25 11:51:03 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:51:03 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:62
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:62) with 1 output partitions
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:62)
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62), which has no missing parents
2021-11-25 11:51:03 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:51:03 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:51:03 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:55927 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:51:03 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:51:03 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:51:03 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:51:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:51:03 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:51:03 INFO  CodeGenerator:54 - Code generated in 162.742416 ms
2021-11-25 11:51:03 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:51:03 INFO  CodeGenerator:54 - Code generated in 40.360417 ms
2021-11-25 11:51:03 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 11:51:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 535 ms on localhost (executor driver) (1/1)
2021-11-25 11:51:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:51:03 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:62) finished in 0.743 s
2021-11-25 11:51:04 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:62, took 0.781394 s
2021-11-25 11:51:04 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:51:04 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:51:04 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:51:04 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:51:04 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:51:04 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:51:04 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:51:04 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:51:04 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:51:04 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:51:04 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-ea836770-2f9b-48b0-ba3a-dfa210b178b8
2021-11-25 11:51:53 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:51:58 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:51:59 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:51:59 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:51:59 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:51:59 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:51:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:51:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:51:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:52:04 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56019.
2021-11-25 11:52:04 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:52:04 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:52:04 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:52:04 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:52:04 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-ace11e31-009b-48c0-8ada-ca267158067a
2021-11-25 11:52:04 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:52:04 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:52:04 INFO  log:192 - Logging initialized @11903ms
2021-11-25 11:52:04 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:52:04 INFO  Server:419 - Started @11951ms
2021-11-25 11:52:04 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:52:04 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:52:04 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:52:04 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:52:04 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56020.
2021-11-25 11:52:04 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56020
2021-11-25 11:52:04 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:52:04 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56020, None)
2021-11-25 11:52:04 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56020 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56020, None)
2021-11-25 11:52:04 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56020, None)
2021-11-25 11:52:04 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56020, None)
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:52:05 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:52:05 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:52:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:52:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:52:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:52:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:52:09 INFO  CodeGenerator:54 - Code generated in 363.427833 ms
2021-11-25 11:52:09 INFO  CodeGenerator:54 - Code generated in 32.629334 ms
2021-11-25 11:52:09 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:52:09 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:52:09 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56020 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:52:09 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:65
2021-11-25 11:52:09 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:52:09 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:65
2021-11-25 11:52:09 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:65) with 1 output partitions
2021-11-25 11:52:09 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:65)
2021-11-25 11:52:09 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:52:09 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:52:09 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:65), which has no missing parents
2021-11-25 11:52:10 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.0 MB)
2021-11-25 11:52:10 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.0 MB)
2021-11-25 11:52:10 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56020 (size: 3.7 KB, free: 912.3 MB)
2021-11-25 11:52:10 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:52:10 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:65) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:52:10 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:52:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:52:10 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:52:10 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:52:10 INFO  CodeGenerator:54 - Code generated in 40.72725 ms
2021-11-25 11:52:10 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1575 bytes result sent to driver
2021-11-25 11:52:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 264 ms on localhost (executor driver) (1/1)
2021-11-25 11:52:10 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:52:10 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:65) finished in 0.411 s
2021-11-25 11:52:10 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:65, took 0.455737 s
2021-11-25 11:52:10 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:52:10 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:52:10 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:52:10 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:52:10 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:52:10 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:52:10 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:52:10 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:52:10 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:52:10 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:52:10 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-19ea3cd6-609d-4160-8ac4-d61f0a8f8576
2021-11-25 11:52:34 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:52:39 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:52:40 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:52:40 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:52:40 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:52:40 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:52:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:52:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:52:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:52:45 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56077.
2021-11-25 11:52:45 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:52:45 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:52:45 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:52:45 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:52:45 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-6ac7b831-144d-4899-ad56-2e20ce1110e1
2021-11-25 11:52:45 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:52:45 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:52:45 INFO  log:192 - Logging initialized @11987ms
2021-11-25 11:52:45 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:52:45 INFO  Server:419 - Started @12033ms
2021-11-25 11:52:45 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:52:45 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:52:45 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:52:46 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:52:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56084.
2021-11-25 11:52:46 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56084
2021-11-25 11:52:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:52:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56084, None)
2021-11-25 11:52:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56084 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56084, None)
2021-11-25 11:52:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56084, None)
2021-11-25 11:52:46 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56084, None)
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:52:46 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:52:46 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:52:49 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:52:49 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:52:49 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:52:49 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:52:50 INFO  CodeGenerator:54 - Code generated in 354.255291 ms
2021-11-25 11:52:50 INFO  CodeGenerator:54 - Code generated in 27.108958 ms
2021-11-25 11:52:50 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:52:50 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:52:50 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56084 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:52:50 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:62
2021-11-25 11:52:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:52:51 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:62
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:62) with 1 output partitions
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:62)
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62), which has no missing parents
2021-11-25 11:52:51 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:52:51 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:52:51 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56084 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:52:51 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:52:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:52:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:52:51 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:52:51 INFO  CodeGenerator:54 - Code generated in 186.577417 ms
2021-11-25 11:52:51 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:52:51 INFO  CodeGenerator:54 - Code generated in 39.925542 ms
2021-11-25 11:52:51 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 11:52:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 571 ms on localhost (executor driver) (1/1)
2021-11-25 11:52:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:52:51 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:62) finished in 0.776 s
2021-11-25 11:52:51 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:62, took 0.822317 s
2021-11-25 11:52:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:52:52 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:52:52 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:52:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:52:52 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:52:52 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:52:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:52:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:52:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:52:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:52:52 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-d248a809-e332-424e-b884-07f42ea0580e
2021-11-25 11:55:52 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:55:57 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:55:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:55:58 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:55:58 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:55:58 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:55:58 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:55:58 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:55:58 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:56:03 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56342.
2021-11-25 11:56:03 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:56:03 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:56:03 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:56:03 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:56:03 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-a9a536a6-bedb-4066-9c9b-623bbbd2b093
2021-11-25 11:56:03 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:56:03 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:56:03 INFO  log:192 - Logging initialized @12230ms
2021-11-25 11:56:03 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:56:03 INFO  Server:419 - Started @12285ms
2021-11-25 11:56:03 INFO  AbstractConnector:278 - Started ServerConnector@7884c166{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:56:03 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a8ab068{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a7e2d9d{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f19b8b3{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/static,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64da2a7{/,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b9d6699{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:56:03 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:56:04 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:56:04 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56343.
2021-11-25 11:56:04 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56343
2021-11-25 11:56:04 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:56:04 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56343, None)
2021-11-25 11:56:04 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56343 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56343, None)
2021-11-25 11:56:04 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56343, None)
2021-11-25 11:56:04 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56343, None)
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5767b2af{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:56:04 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f012914{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@732bb66d{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5395ea39{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:56:04 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:56:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:56:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:56:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:56:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:56:08 INFO  CodeGenerator:54 - Code generated in 440.796708 ms
2021-11-25 11:56:09 INFO  CodeGenerator:54 - Code generated in 31.806791 ms
2021-11-25 11:56:09 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:56:09 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:56:09 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56343 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:56:09 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:62
2021-11-25 11:56:09 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:56:09 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:62
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:62) with 1 output partitions
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:62)
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62), which has no missing parents
2021-11-25 11:56:09 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.8 KB, free 912.0 MB)
2021-11-25 11:56:09 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:56:09 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56343 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:56:09 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:56:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:56:09 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:56:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:56:09 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:56:10 INFO  CodeGenerator:54 - Code generated in 167.766167 ms
2021-11-25 11:56:10 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:56:10 INFO  CodeGenerator:54 - Code generated in 36.592708 ms
2021-11-25 11:56:10 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1505 bytes result sent to driver
2021-11-25 11:56:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 599 ms on localhost (executor driver) (1/1)
2021-11-25 11:56:10 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:56:10 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:62) finished in 0.847 s
2021-11-25 11:56:10 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:62, took 0.899691 s
2021-11-25 11:56:10 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:56:10 INFO  AbstractConnector:318 - Stopped Spark@7884c166{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:56:10 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:56:11 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:56:11 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:56:11 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:56:11 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:56:11 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:56:11 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:56:11 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:56:11 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-48db9f7f-38e1-4100-b0e1-f6d38ee9aefc
2021-11-25 11:57:50 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 11:57:55 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 11:57:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 11:57:55 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 11:57:56 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 11:57:56 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 11:57:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 11:57:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 11:57:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 11:58:01 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56513.
2021-11-25 11:58:01 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 11:58:01 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 11:58:01 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 11:58:01 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 11:58:01 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-901e2ec9-f358-49b0-8ca1-d529a6b78e09
2021-11-25 11:58:01 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 11:58:01 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 11:58:01 INFO  log:192 - Logging initialized @12063ms
2021-11-25 11:58:01 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 11:58:01 INFO  Server:419 - Started @12122ms
2021-11-25 11:58:01 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:58:01 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 11:58:01 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 11:58:01 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 11:58:01 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56516.
2021-11-25 11:58:01 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56516
2021-11-25 11:58:01 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 11:58:01 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56516, None)
2021-11-25 11:58:01 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56516 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56516, None)
2021-11-25 11:58:01 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56516, None)
2021-11-25 11:58:01 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56516, None)
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 11:58:02 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 11:58:02 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 11:58:05 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 11:58:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 11:58:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 11:58:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 11:58:06 INFO  CodeGenerator:54 - Code generated in 354.889167 ms
2021-11-25 11:58:06 INFO  CodeGenerator:54 - Code generated in 29.984625 ms
2021-11-25 11:58:06 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 11:58:07 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 11:58:07 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56516 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 11:58:07 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:62
2021-11-25 11:58:07 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 11:58:07 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:62
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:62) with 1 output partitions
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:62)
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62), which has no missing parents
2021-11-25 11:58:07 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 912.0 MB)
2021-11-25 11:58:07 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 11:58:07 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56516 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 11:58:07 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:62) (first 15 tasks are for partitions Vector(0))
2021-11-25 11:58:07 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 11:58:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 11:58:07 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 11:58:07 INFO  CodeGenerator:54 - Code generated in 150.474834 ms
2021-11-25 11:58:07 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 11:58:07 INFO  CodeGenerator:54 - Code generated in 35.667459 ms
2021-11-25 11:58:07 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1505 bytes result sent to driver
2021-11-25 11:58:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 525 ms on localhost (executor driver) (1/1)
2021-11-25 11:58:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 11:58:07 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:62) finished in 0.732 s
2021-11-25 11:58:07 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:62, took 0.777723 s
2021-11-25 11:58:08 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 11:58:08 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 11:58:08 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 11:58:08 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 11:58:08 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 11:58:08 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 11:58:08 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 11:58:08 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 11:58:08 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 11:58:08 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 11:58:08 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-1a9a9b21-8e89-4efe-8d0a-095485dc504a
2021-11-25 11:59:54 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:00:00 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:00:00 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:00:00 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:00:00 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:00:00 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:00:00 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:00:00 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:00:00 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:00:05 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56695.
2021-11-25 12:00:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:00:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:00:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:00:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:00:06 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-3730538d-b7c6-44f8-bc5c-824790e8d291
2021-11-25 12:00:06 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:00:06 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:00:06 INFO  log:192 - Logging initialized @12334ms
2021-11-25 12:00:06 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:00:06 INFO  Server:419 - Started @12407ms
2021-11-25 12:00:06 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:00:06 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:00:06 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:00:06 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:00:06 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56696.
2021-11-25 12:00:06 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56696
2021-11-25 12:00:06 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:00:06 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56696, None)
2021-11-25 12:00:06 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56696 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56696, None)
2021-11-25 12:00:06 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56696, None)
2021-11-25 12:00:06 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56696, None)
2021-11-25 12:00:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:00:07 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:00:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60baef24{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad5923a{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4463d9d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13d186db{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:00:07 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:00:11 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:00:11 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:00:11 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:00:11 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:00:11 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:00:11 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:00:11 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:00:11 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:00:11 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:00:11 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:00:11 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-c214c30d-631e-4ecc-95bc-0b84421234d4
2021-11-25 12:00:29 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:00:35 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:00:41 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:00:46 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:00:47 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:00:47 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:00:47 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:00:47 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:00:47 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:00:47 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:00:47 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:00:52 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56769.
2021-11-25 12:00:52 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:00:52 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:00:52 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:00:52 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:00:52 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-9c34a79f-eed5-4afe-8e1d-49d3aa88f20c
2021-11-25 12:00:52 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:00:52 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:00:53 INFO  log:192 - Logging initialized @12318ms
2021-11-25 12:00:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:00:53 INFO  Server:419 - Started @12445ms
2021-11-25 12:00:53 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:00:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:00:53 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:00:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56770.
2021-11-25 12:00:53 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56770
2021-11-25 12:00:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:00:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56770, None)
2021-11-25 12:00:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56770 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56770, None)
2021-11-25 12:00:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56770, None)
2021-11-25 12:00:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56770, None)
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3cc20577{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:00:53 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c9d82f9{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f012914{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@732bb66d{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:00:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43b0ade{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:00:54 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:00:59 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 12:00:59 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 12:00:59 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 12:00:59 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 12:01:00 INFO  CodeGenerator:54 - Code generated in 384.859584 ms
2021-11-25 12:01:00 INFO  CodeGenerator:54 - Code generated in 30.423708 ms
2021-11-25 12:01:00 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 12:01:00 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 12:01:00 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56770 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 12:01:00 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:59
2021-11-25 12:01:00 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 12:01:00 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:59
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:59) with 1 output partitions
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:59)
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:59), which has no missing parents
2021-11-25 12:01:00 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 12:01:00 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 12:01:00 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56770 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 12:01:00 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 12:01:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:59) (first 15 tasks are for partitions Vector(0))
2021-11-25 12:01:00 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 12:01:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 12:01:00 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 12:01:01 INFO  CodeGenerator:54 - Code generated in 121.084042 ms
2021-11-25 12:01:01 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 12:01:01 INFO  CodeGenerator:54 - Code generated in 69.810292 ms
2021-11-25 12:01:01 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 12:01:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 576 ms on localhost (executor driver) (1/1)
2021-11-25 12:01:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 12:01:01 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:59) finished in 0.798 s
2021-11-25 12:01:01 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:59, took 0.843011 s
2021-11-25 12:01:02 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:01:02 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:01:02 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:01:02 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:01:02 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:01:02 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:01:02 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:01:02 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:01:02 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:01:02 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:01:02 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-353f73c0-11c4-4783-973f-c6e4539ce02e
2021-11-25 12:01:30 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:01:36 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:01:36 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:01:36 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:01:36 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:01:36 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:01:36 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:01:36 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:01:36 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:01:42 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 56839.
2021-11-25 12:01:42 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:01:42 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:01:42 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:01:42 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:01:42 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-7aeafb84-513c-4d96-b86e-2e13c9958f90
2021-11-25 12:01:42 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:01:42 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:01:42 INFO  log:192 - Logging initialized @12129ms
2021-11-25 12:01:42 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:01:42 INFO  Server:419 - Started @12179ms
2021-11-25 12:01:42 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:01:42 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:01:42 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:01:42 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:01:42 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56840.
2021-11-25 12:01:42 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:56840
2021-11-25 12:01:42 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:01:42 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 56840, None)
2021-11-25 12:01:42 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:56840 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 56840, None)
2021-11-25 12:01:42 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 56840, None)
2021-11-25 12:01:42 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 56840, None)
2021-11-25 12:01:42 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:01:43 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:01:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:01:43 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:01:45 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 12:01:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 12:01:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 12:01:46 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 12:01:46 INFO  CodeGenerator:54 - Code generated in 228.490834 ms
2021-11-25 12:01:46 INFO  CodeGenerator:54 - Code generated in 37.565 ms
2021-11-25 12:01:47 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 12:01:47 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 12:01:47 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:56840 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 12:01:47 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:45
2021-11-25 12:01:47 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 12:01:47 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:45
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:45) with 1 output partitions
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:45)
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:45), which has no missing parents
2021-11-25 12:01:47 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.0 MB)
2021-11-25 12:01:47 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.0 MB)
2021-11-25 12:01:47 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:56840 (size: 3.7 KB, free: 912.3 MB)
2021-11-25 12:01:47 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 12:01:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:45) (first 15 tasks are for partitions Vector(0))
2021-11-25 12:01:47 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 12:01:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 12:01:47 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 12:01:47 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 12:01:47 INFO  CodeGenerator:54 - Code generated in 31.399417 ms
2021-11-25 12:01:48 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1575 bytes result sent to driver
2021-11-25 12:01:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 324 ms on localhost (executor driver) (1/1)
2021-11-25 12:01:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 12:01:48 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:45) finished in 0.485 s
2021-11-25 12:01:48 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:45, took 0.580587 s
2021-11-25 12:01:48 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:01:48 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:01:48 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:01:48 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:01:48 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:01:48 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:01:48 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:01:48 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:01:48 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:01:48 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:01:48 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-dd727fe0-e662-4161-909c-f43b35b82b06
2021-11-25 12:18:22 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:18:27 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:18:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:18:28 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:18:28 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:18:28 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:18:28 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:18:28 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:18:28 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:18:33 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 58109.
2021-11-25 12:18:33 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:18:33 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:18:33 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:18:33 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:18:33 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-5bff9052-538d-41a3-b97d-6006613f5699
2021-11-25 12:18:33 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:18:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:18:33 INFO  log:192 - Logging initialized @12121ms
2021-11-25 12:18:33 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:18:33 INFO  Server:419 - Started @12178ms
2021-11-25 12:18:33 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:18:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:18:33 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:18:33 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:18:33 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58110.
2021-11-25 12:18:33 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:58110
2021-11-25 12:18:33 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:18:33 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 58110, None)
2021-11-25 12:18:33 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:58110 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 58110, None)
2021-11-25 12:18:33 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 58110, None)
2021-11-25 12:18:33 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 58110, None)
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:18:34 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:18:34 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:18:37 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 12:18:37 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 12:18:37 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 12:18:37 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 12:18:37 INFO  CodeGenerator:54 - Code generated in 255.242208 ms
2021-11-25 12:18:38 INFO  CodeGenerator:54 - Code generated in 28.564084 ms
2021-11-25 12:18:38 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 12:18:38 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 12:18:38 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:58110 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 12:18:38 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:47
2021-11-25 12:18:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 12:18:38 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:47
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:47) with 1 output partitions
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:47)
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47), which has no missing parents
2021-11-25 12:18:38 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 12:18:38 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 12:18:38 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:58110 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 12:18:38 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 12:18:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47) (first 15 tasks are for partitions Vector(0))
2021-11-25 12:18:38 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 12:18:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 12:18:39 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 12:18:39 INFO  CodeGenerator:54 - Code generated in 28.484625 ms
2021-11-25 12:18:39 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 12:18:39 INFO  CodeGenerator:54 - Code generated in 45.133917 ms
2021-11-25 12:18:39 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1804 bytes result sent to driver
2021-11-25 12:18:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 383 ms on localhost (executor driver) (1/1)
2021-11-25 12:18:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 12:18:39 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:47) finished in 0.535 s
2021-11-25 12:18:39 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:47, took 0.573044 s
2021-11-25 12:18:39 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:18:39 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:18:39 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:18:39 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:18:39 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:18:39 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:18:39 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:18:39 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:18:39 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:18:39 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:18:39 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-c482ab48-e860-423f-8fac-86b200b7e412
2021-11-25 12:19:32 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:19:37 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:19:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:19:38 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:19:38 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:19:38 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:19:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:19:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:19:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:19:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 58210.
2021-11-25 12:19:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:19:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:19:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:19:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:19:43 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-a0c38558-fa0b-470b-b9b2-462f98d49780
2021-11-25 12:19:43 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:19:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:19:43 INFO  log:192 - Logging initialized @12095ms
2021-11-25 12:19:43 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:19:43 INFO  Server:419 - Started @12142ms
2021-11-25 12:19:43 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:19:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:19:43 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:19:44 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:19:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58211.
2021-11-25 12:19:44 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:58211
2021-11-25 12:19:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:19:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 58211, None)
2021-11-25 12:19:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:58211 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 58211, None)
2021-11-25 12:19:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 58211, None)
2021-11-25 12:19:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 58211, None)
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:44 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:19:44 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:19:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:19:45 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:19:47 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 12:19:47 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 12:19:47 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 12:19:47 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 12:19:48 INFO  CodeGenerator:54 - Code generated in 298.79225 ms
2021-11-25 12:19:48 INFO  CodeGenerator:54 - Code generated in 27.550667 ms
2021-11-25 12:19:48 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 12:19:48 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 12:19:48 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:58211 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 12:19:48 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:47
2021-11-25 12:19:48 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 12:19:48 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:47
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:47) with 1 output partitions
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:47)
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47), which has no missing parents
2021-11-25 12:19:49 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 12:19:49 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 12:19:49 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:58211 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 12:19:49 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47) (first 15 tasks are for partitions Vector(0))
2021-11-25 12:19:49 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 12:19:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 12:19:49 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 12:19:49 INFO  CodeGenerator:54 - Code generated in 28.166917 ms
2021-11-25 12:19:49 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 12:19:49 INFO  CodeGenerator:54 - Code generated in 30.831875 ms
2021-11-25 12:19:49 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1804 bytes result sent to driver
2021-11-25 12:19:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 400 ms on localhost (executor driver) (1/1)
2021-11-25 12:19:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 12:19:49 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:47) finished in 0.568 s
2021-11-25 12:19:49 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:47, took 0.611727 s
2021-11-25 12:19:49 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:19:49 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:19:49 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:19:49 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:19:49 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:19:49 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:19:50 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:19:50 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:19:50 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:19:50 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:19:50 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-52afe1e8-6ac1-42d9-a69a-b703dec0b26a
2021-11-25 12:30:43 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:30:48 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:30:49 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:30:49 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:30:49 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:30:49 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:30:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:30:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:30:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:30:54 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 59154.
2021-11-25 12:30:54 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:30:54 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:30:54 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:30:54 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:30:54 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-e6a484c3-8f7d-406d-bc69-fd65e8457964
2021-11-25 12:30:54 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:30:54 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:30:54 INFO  log:192 - Logging initialized @12118ms
2021-11-25 12:30:54 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:30:54 INFO  Server:419 - Started @12169ms
2021-11-25 12:30:54 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:30:54 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:30:55 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:30:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59161.
2021-11-25 12:30:55 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:59161
2021-11-25 12:30:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:30:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 59161, None)
2021-11-25 12:30:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:59161 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 59161, None)
2021-11-25 12:30:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 59161, None)
2021-11-25 12:30:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 59161, None)
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:30:55 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:30:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:30:56 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:30:58 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:30:58 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:30:58 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:30:58 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:30:58 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:30:58 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:30:58 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:30:58 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:30:58 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:30:58 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:30:58 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-377b1727-cd38-4d19-a3fa-7bbcbfb506ae
2021-11-25 12:31:58 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:32:03 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:32:04 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:32:04 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:32:04 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:32:04 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:32:04 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:32:04 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:32:04 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:32:10 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 12:32:15 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 12:32:16 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 12:32:16 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 12:32:16 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 12:32:16 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 12:32:16 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 12:32:16 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 12:32:16 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 12:32:21 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 59285.
2021-11-25 12:32:21 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 12:32:21 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 12:32:21 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 12:32:21 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 12:32:21 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-2ac73a0c-af46-4646-b9ea-ebc735a30882
2021-11-25 12:32:21 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 12:32:21 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 12:32:21 INFO  log:192 - Logging initialized @12063ms
2021-11-25 12:32:21 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 12:32:21 INFO  Server:419 - Started @12119ms
2021-11-25 12:32:21 INFO  AbstractConnector:278 - Started ServerConnector@48c75c1f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:32:21 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74cec793{/jobs,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a82f33{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/stages,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/storage,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/environment,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/executors,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/static,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/api,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 12:32:21 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 12:32:22 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 12:32:22 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59286.
2021-11-25 12:32:22 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:59286
2021-11-25 12:32:22 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 12:32:22 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 59286, None)
2021-11-25 12:32:22 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:59286 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 59286, None)
2021-11-25 12:32:22 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 59286, None)
2021-11-25 12:32:22 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 59286, None)
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32639b12{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:22 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 12:32:22 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c2327fa{/SQL,null,AVAILABLE,@Spark}
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3605c4d3{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 12:32:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ff57625{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 12:32:23 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 12:32:25 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 12:32:25 INFO  AbstractConnector:318 - Stopped Spark@48c75c1f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 12:32:25 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 12:32:25 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 12:32:25 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 12:32:25 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 12:32:25 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 12:32:25 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 12:32:25 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 12:32:25 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 12:32:25 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-cd53ba26-adc3-486e-b9c3-8925ba9eb8c9
2021-11-25 13:29:34 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:29:39 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:29:40 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:29:40 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:29:40 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:29:40 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:29:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:29:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:29:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:29:45 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60050.
2021-11-25 13:29:45 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:29:45 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:29:45 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:29:45 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:29:45 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-91e901de-0ca5-41e2-a7cc-34da494dfb96
2021-11-25 13:29:45 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:29:45 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:29:45 INFO  log:192 - Logging initialized @12143ms
2021-11-25 13:29:45 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:29:45 INFO  Server:419 - Started @12195ms
2021-11-25 13:29:45 INFO  AbstractConnector:278 - Started ServerConnector@1cb8dac0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:29:45 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74cec793{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a82f33{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/static,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/api,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:29:45 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:29:46 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:29:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60051.
2021-11-25 13:29:46 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:60051
2021-11-25 13:29:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:29:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 60051, None)
2021-11-25 13:29:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:60051 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 60051, None)
2021-11-25 13:29:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 60051, None)
2021-11-25 13:29:46 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 60051, None)
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32639b12{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:46 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:29:46 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c2327fa{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3605c4d3{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:29:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ff57625{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:29:47 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:29:49 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:29:49 INFO  AbstractConnector:318 - Stopped Spark@1cb8dac0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:29:49 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:29:49 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:29:49 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:29:49 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:29:49 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:29:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:29:49 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:29:49 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:29:49 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-3642cd07-ed76-48de-96a0-50e0f95c07d6
2021-11-25 13:30:13 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:30:18 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:30:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:30:19 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:30:19 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:30:19 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:30:19 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:30:19 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:30:19 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:30:24 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60108.
2021-11-25 13:30:24 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:30:24 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:30:24 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:30:24 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:30:24 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-190bd524-affc-4fcf-9320-fe5fa3439e77
2021-11-25 13:30:24 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:30:24 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:30:24 INFO  log:192 - Logging initialized @12003ms
2021-11-25 13:30:24 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:30:24 INFO  Server:419 - Started @12052ms
2021-11-25 13:30:24 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:30:24 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:30:24 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:30:24 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:30:24 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60109.
2021-11-25 13:30:24 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:60109
2021-11-25 13:30:24 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:30:25 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 60109, None)
2021-11-25 13:30:25 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:60109 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 60109, None)
2021-11-25 13:30:25 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 60109, None)
2021-11-25 13:30:25 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 60109, None)
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:30:25 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:30:25 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:30:28 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:30:28 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:30:28 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:30:28 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:30:28 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:30:28 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:30:28 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:30:28 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:30:28 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:30:28 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:30:28 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-c78d985c-06d0-429a-bada-6e583055fd25
2021-11-25 13:39:17 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:39:23 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:39:23 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:39:23 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:39:24 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:39:24 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:39:24 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:39:24 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:39:24 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:39:29 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60891.
2021-11-25 13:39:29 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:39:29 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:39:29 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:39:29 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:39:29 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-2e23c84f-5672-4f06-b85c-663e757e6338
2021-11-25 13:39:29 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:39:29 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:39:29 INFO  log:192 - Logging initialized @12437ms
2021-11-25 13:39:29 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:39:29 INFO  Server:419 - Started @12536ms
2021-11-25 13:39:29 INFO  AbstractConnector:278 - Started ServerConnector@314b8f2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:39:29 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21c64522{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a7e2d9d{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f08c4b{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f19b8b3{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/static,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@114a85c2{/,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f415a95{/api,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:39:29 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:39:30 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:39:30 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60892.
2021-11-25 13:39:30 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:60892
2021-11-25 13:39:30 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:39:30 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 60892, None)
2021-11-25 13:39:30 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:60892 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 60892, None)
2021-11-25 13:39:30 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 60892, None)
2021-11-25 13:39:30 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 60892, None)
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e521715{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:30 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:39:30 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8326a4{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77128dab{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f012914{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:30 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:39:31 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:39:34 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:39:34 INFO  AbstractConnector:318 - Stopped Spark@314b8f2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:39:34 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:39:34 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:39:34 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:39:34 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:39:34 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:39:34 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:39:34 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:39:34 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:39:34 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-f0ecd49a-b31b-48b9-a4f8-dd0ed0732e68
2021-11-25 13:39:40 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:39:45 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:39:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:39:45 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:39:46 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:39:46 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:39:46 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:39:46 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:39:46 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:39:51 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60923.
2021-11-25 13:39:51 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:39:51 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:39:51 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:39:51 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:39:51 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-af3b8ba1-4ed5-4b33-9e3b-5aa5c3c22475
2021-11-25 13:39:51 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:39:51 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:39:51 INFO  log:192 - Logging initialized @11998ms
2021-11-25 13:39:51 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:39:51 INFO  Server:419 - Started @12058ms
2021-11-25 13:39:51 INFO  AbstractConnector:278 - Started ServerConnector@314b8f2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:39:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21c64522{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a7e2d9d{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f08c4b{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f19b8b3{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/static,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@114a85c2{/,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f415a95{/api,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:39:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:39:51 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:39:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60924.
2021-11-25 13:39:51 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:60924
2021-11-25 13:39:51 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:39:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 60924, None)
2021-11-25 13:39:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:60924 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 60924, None)
2021-11-25 13:39:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 60924, None)
2021-11-25 13:39:51 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 60924, None)
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e521715{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:39:52 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ff57625{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69ce2f62{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c9d82f9{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:39:52 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:39:55 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:39:55 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:39:55 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:39:55 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:39:55 INFO  CodeGenerator:54 - Code generated in 252.279709 ms
2021-11-25 13:39:56 INFO  CodeGenerator:54 - Code generated in 34.245833 ms
2021-11-25 13:39:56 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:39:56 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:39:56 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:60924 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:39:56 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:47
2021-11-25 13:39:56 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:39:56 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:47
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:47) with 1 output partitions
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:47)
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47), which has no missing parents
2021-11-25 13:39:56 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 13:39:56 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 13:39:56 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:60924 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 13:39:56 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:47) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:39:56 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:39:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:39:56 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:39:56 INFO  CodeGenerator:54 - Code generated in 26.190875 ms
2021-11-25 13:39:56 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:39:56 INFO  CodeGenerator:54 - Code generated in 23.441625 ms
2021-11-25 13:39:56 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1804 bytes result sent to driver
2021-11-25 13:39:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 325 ms on localhost (executor driver) (1/1)
2021-11-25 13:39:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:39:56 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:47) finished in 0.503 s
2021-11-25 13:39:56 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:47, took 0.542701 s
2021-11-25 13:39:56 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:39:56 INFO  AbstractConnector:318 - Stopped Spark@314b8f2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:39:56 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:39:56 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:39:57 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:39:57 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:39:57 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:39:57 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:39:57 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:39:57 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:39:57 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-0fad7a02-195a-4c3f-ba33-0cfa4bf135d0
2021-11-25 13:42:04 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:42:10 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:42:10 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:42:10 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:42:10 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:42:10 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:42:10 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:42:10 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:42:10 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:42:15 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61111.
2021-11-25 13:42:16 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:42:16 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:42:16 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:42:16 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:42:16 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-d06bf901-2b33-43c9-9d48-3cd965d7c050
2021-11-25 13:42:16 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:42:16 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:42:16 INFO  log:192 - Logging initialized @12068ms
2021-11-25 13:42:16 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:42:16 INFO  Server:419 - Started @12116ms
2021-11-25 13:42:16 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:42:16 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:42:16 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:42:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61112.
2021-11-25 13:42:16 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:61112
2021-11-25 13:42:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:42:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 61112, None)
2021-11-25 13:42:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:61112 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 61112, None)
2021-11-25 13:42:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 61112, None)
2021-11-25 13:42:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 61112, None)
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:42:16 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:42:17 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:42:20 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:42:20 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:42:20 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:42:20 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:42:20 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:42:20 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:42:20 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:42:20 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:42:20 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:42:20 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:42:20 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-63b6f885-ba4d-46c2-ab78-acedb31fd719
2021-11-25 13:42:33 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:42:39 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:42:39 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:42:39 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:42:39 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:42:39 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:42:39 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:42:39 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:42:39 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:42:45 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61156.
2021-11-25 13:42:45 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:42:45 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:42:45 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:42:45 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:42:45 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-362ccd75-55f5-4c2e-b09c-0d33793ad6de
2021-11-25 13:42:45 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:42:45 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:42:45 INFO  log:192 - Logging initialized @11995ms
2021-11-25 13:42:45 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:42:45 INFO  Server:419 - Started @12043ms
2021-11-25 13:42:45 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:42:45 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:42:45 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:42:45 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61157.
2021-11-25 13:42:45 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:61157
2021-11-25 13:42:45 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:42:45 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 61157, None)
2021-11-25 13:42:45 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:61157 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 61157, None)
2021-11-25 13:42:45 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 61157, None)
2021-11-25 13:42:45 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 61157, None)
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:42:45 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:42:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:42:46 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:42:49 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:42:49 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:42:49 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:42:49 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:42:49 INFO  CodeGenerator:54 - Code generated in 322.674375 ms
2021-11-25 13:42:50 INFO  CodeGenerator:54 - Code generated in 34.10475 ms
2021-11-25 13:42:50 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:42:50 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:42:50 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:61157 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:42:50 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:49
2021-11-25 13:42:50 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:42:50 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:49
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:49) with 1 output partitions
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:49)
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:49), which has no missing parents
2021-11-25 13:42:50 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 912.0 MB)
2021-11-25 13:42:50 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 912.0 MB)
2021-11-25 13:42:50 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:61157 (size: 5.4 KB, free: 912.3 MB)
2021-11-25 13:42:50 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:49) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:42:50 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:42:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:42:50 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:42:50 INFO  CodeGenerator:54 - Code generated in 28.412 ms
2021-11-25 13:42:50 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:42:50 INFO  CodeGenerator:54 - Code generated in 17.257167 ms
2021-11-25 13:42:50 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1484 bytes result sent to driver
2021-11-25 13:42:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 308 ms on localhost (executor driver) (1/1)
2021-11-25 13:42:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:42:50 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:49) finished in 0.463 s
2021-11-25 13:42:50 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:49, took 0.502869 s
2021-11-25 13:42:50 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:42:50 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:42:50 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:42:50 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:42:50 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:42:50 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:42:50 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:42:50 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:42:50 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:42:50 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:42:50 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-5039f89d-22c9-4416-81b3-74547af50bbd
2021-11-25 13:45:01 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:45:07 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:45:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:45:07 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:45:07 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:45:07 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:45:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:45:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:45:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:45:13 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61355.
2021-11-25 13:45:13 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:45:13 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:45:13 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:45:13 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:45:13 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-9c5c9e16-0f16-4a34-9f9d-60c90731acdb
2021-11-25 13:45:13 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:45:13 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:45:13 INFO  log:192 - Logging initialized @11910ms
2021-11-25 13:45:13 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:45:13 INFO  Server:419 - Started @11978ms
2021-11-25 13:45:13 INFO  AbstractConnector:278 - Started ServerConnector@76333740{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:45:13 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74cec793{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a82f33{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/static,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/api,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:45:13 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:45:13 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:45:13 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61362.
2021-11-25 13:45:13 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:61362
2021-11-25 13:45:13 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:45:13 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 61362, None)
2021-11-25 13:45:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:61362 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 61362, None)
2021-11-25 13:45:13 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 61362, None)
2021-11-25 13:45:13 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 61362, None)
2021-11-25 13:45:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32639b12{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:45:14 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:45:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c2327fa{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3605c4d3{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ff57625{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:45:14 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:45:17 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:45:17 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:45:17 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:45:17 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:45:17 INFO  CodeGenerator:54 - Code generated in 293.491917 ms
2021-11-25 13:45:17 INFO  CodeGenerator:54 - Code generated in 27.212916 ms
2021-11-25 13:45:18 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:45:18 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:45:18 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:61362 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:45:18 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:48
2021-11-25 13:45:18 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:45:18 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:48
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:48) with 1 output partitions
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:48)
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:48), which has no missing parents
2021-11-25 13:45:18 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 13:45:18 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 13:45:18 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:61362 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 13:45:18 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:48) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:45:18 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:45:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:45:18 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:45:18 INFO  CodeGenerator:54 - Code generated in 33.556208 ms
2021-11-25 13:45:18 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:45:18 INFO  CodeGenerator:54 - Code generated in 21.417708 ms
2021-11-25 13:45:18 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1482 bytes result sent to driver
2021-11-25 13:45:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 311 ms on localhost (executor driver) (1/1)
2021-11-25 13:45:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:45:18 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:48) finished in 0.531 s
2021-11-25 13:45:18 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:48, took 0.572348 s
2021-11-25 13:45:18 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:45:18 INFO  AbstractConnector:318 - Stopped Spark@76333740{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:45:18 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:45:18 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:45:18 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:45:18 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:45:18 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:45:18 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:45:18 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:45:18 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:45:18 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-ea1d0f61-cac4-4c30-b5dc-a6ad5adea8bc
2021-11-25 13:47:34 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:47:39 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:47:40 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:47:40 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:47:40 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:47:40 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:47:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:47:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:47:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:47:45 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61554.
2021-11-25 13:47:45 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:47:45 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:47:45 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:47:45 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:47:45 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-68af0c20-d727-444f-bf4e-4dd5dd3c3e7d
2021-11-25 13:47:45 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:47:45 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:47:45 INFO  log:192 - Logging initialized @12110ms
2021-11-25 13:47:45 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:47:45 INFO  Server:419 - Started @12165ms
2021-11-25 13:47:45 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:47:45 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:47:45 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:47:46 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:47:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61555.
2021-11-25 13:47:46 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:61555
2021-11-25 13:47:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:47:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 61555, None)
2021-11-25 13:47:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:61555 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 61555, None)
2021-11-25 13:47:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 61555, None)
2021-11-25 13:47:46 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 61555, None)
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:47:46 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60baef24{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad5923a{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4463d9d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13d186db{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:47:46 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:47:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:47:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:47:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:47:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:47:50 INFO  CodeGenerator:54 - Code generated in 331.556291 ms
2021-11-25 13:47:50 INFO  CodeGenerator:54 - Code generated in 30.002041 ms
2021-11-25 13:47:50 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:47:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:47:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:61555 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:47:51 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:58
2021-11-25 13:47:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:47:51 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:58
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:58) with 1 output partitions
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:58)
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58), which has no missing parents
2021-11-25 13:47:51 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 13:47:51 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 13:47:51 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:61555 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 13:47:51 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:47:51 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:47:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:47:51 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:47:51 INFO  CodeGenerator:54 - Code generated in 152.693458 ms
2021-11-25 13:47:51 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:47:51 INFO  CodeGenerator:54 - Code generated in 50.201083 ms
2021-11-25 13:47:51 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 13:47:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 570 ms on localhost (executor driver) (1/1)
2021-11-25 13:47:51 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:47:51 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:58) finished in 0.768 s
2021-11-25 13:47:51 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:58, took 0.809065 s
2021-11-25 13:47:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:47:52 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:47:52 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:47:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:47:52 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:47:52 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:47:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:47:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:47:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:47:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:47:52 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-337aa36f-6ea9-40ff-85e3-c93f2e4a34c1
2021-11-25 13:49:00 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:49:05 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:49:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:49:06 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:49:06 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:49:06 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:49:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:49:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:49:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:49:11 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 61686.
2021-11-25 13:49:11 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:49:11 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:49:11 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:49:11 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:49:11 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-3b77940d-db72-46ca-8024-6c41f8fc9ac1
2021-11-25 13:49:11 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:49:11 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:49:11 INFO  log:192 - Logging initialized @12068ms
2021-11-25 13:49:11 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:49:11 INFO  Server:419 - Started @12116ms
2021-11-25 13:49:11 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:49:11 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:49:11 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:49:12 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:49:12 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61687.
2021-11-25 13:49:12 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:61687
2021-11-25 13:49:12 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:49:12 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 61687, None)
2021-11-25 13:49:12 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:61687 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 61687, None)
2021-11-25 13:49:12 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 61687, None)
2021-11-25 13:49:12 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 61687, None)
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:49:12 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:49:12 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:49:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:49:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:49:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:49:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:49:16 INFO  CodeGenerator:54 - Code generated in 335.092583 ms
2021-11-25 13:49:16 INFO  CodeGenerator:54 - Code generated in 25.399083 ms
2021-11-25 13:49:16 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:49:16 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:49:16 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:61687 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:49:16 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:58
2021-11-25 13:49:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:49:17 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:58
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:58) with 1 output partitions
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:58)
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58), which has no missing parents
2021-11-25 13:49:17 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 13:49:17 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 13:49:17 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:61687 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 13:49:17 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:49:17 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:49:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:49:17 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:49:17 INFO  CodeGenerator:54 - Code generated in 172.181917 ms
2021-11-25 13:49:17 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:49:17 INFO  CodeGenerator:54 - Code generated in 47.693542 ms
2021-11-25 13:49:17 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 13:49:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 711 ms on localhost (executor driver) (1/1)
2021-11-25 13:49:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:49:17 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:58) finished in 0.920 s
2021-11-25 13:49:17 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:58, took 0.962087 s
2021-11-25 13:49:18 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:49:18 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:49:18 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:49:18 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:49:18 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:49:18 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:49:18 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:49:18 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:49:18 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:49:18 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:49:18 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-ba4d65f1-2db5-4b1c-835a-0f80fd8eaf63
2021-11-25 13:53:59 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:54:04 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:54:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:54:05 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:54:05 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:54:05 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:54:05 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:54:05 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:54:05 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:54:10 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62067.
2021-11-25 13:54:10 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:54:10 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:54:10 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:54:10 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:54:10 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-5441b349-e12c-408a-888f-dea41a55e227
2021-11-25 13:54:10 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:54:10 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:54:10 INFO  log:192 - Logging initialized @12160ms
2021-11-25 13:54:11 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:54:11 INFO  Server:419 - Started @12214ms
2021-11-25 13:54:11 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:54:11 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:54:11 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:54:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62068.
2021-11-25 13:54:11 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:62068
2021-11-25 13:54:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:54:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 62068, None)
2021-11-25 13:54:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:62068 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 62068, None)
2021-11-25 13:54:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 62068, None)
2021-11-25 13:54:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 62068, None)
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:54:11 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:54:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:54:12 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:54:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:54:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:54:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:54:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:54:15 INFO  CodeGenerator:54 - Code generated in 349.080875 ms
2021-11-25 13:54:16 INFO  CodeGenerator:54 - Code generated in 34.355417 ms
2021-11-25 13:54:16 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:54:16 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:54:16 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:62068 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:54:16 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:58
2021-11-25 13:54:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:54:16 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:58
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:58) with 1 output partitions
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:58)
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58), which has no missing parents
2021-11-25 13:54:16 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 13:54:16 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 912.0 MB)
2021-11-25 13:54:16 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:62068 (size: 6.3 KB, free: 912.3 MB)
2021-11-25 13:54:16 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:54:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:54:16 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:54:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:54:16 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:54:17 INFO  CodeGenerator:54 - Code generated in 168.889083 ms
2021-11-25 13:54:17 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:54:17 INFO  CodeGenerator:54 - Code generated in 39.3185 ms
2021-11-25 13:54:17 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 13:54:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 586 ms on localhost (executor driver) (1/1)
2021-11-25 13:54:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:54:17 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:58) finished in 0.806 s
2021-11-25 13:54:17 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:58, took 0.855806 s
2021-11-25 13:54:17 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:54:17 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:54:17 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:54:17 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:54:17 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:54:17 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:54:17 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:54:17 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:54:17 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:54:17 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:54:17 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-22792375-d6ce-4501-922c-ca62206508f6
2021-11-25 13:55:05 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:55:10 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:55:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:55:11 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:55:11 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:55:11 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:55:11 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:55:11 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:55:11 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:55:16 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62157.
2021-11-25 13:55:16 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:55:16 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:55:16 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:55:16 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:55:16 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-826c4422-edd5-4669-8c23-530df48a0c2d
2021-11-25 13:55:16 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:55:16 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:55:16 INFO  log:192 - Logging initialized @11952ms
2021-11-25 13:55:16 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:55:16 INFO  Server:419 - Started @12006ms
2021-11-25 13:55:16 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:55:16 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:55:16 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:55:17 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:55:17 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62158.
2021-11-25 13:55:17 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:62158
2021-11-25 13:55:17 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:55:17 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 62158, None)
2021-11-25 13:55:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:62158 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 62158, None)
2021-11-25 13:55:17 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 62158, None)
2021-11-25 13:55:17 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 62158, None)
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:55:17 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:55:18 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:55:21 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:55:21 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:55:21 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:55:21 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:55:21 INFO  CodeGenerator:54 - Code generated in 396.520333 ms
2021-11-25 13:55:21 INFO  CodeGenerator:54 - Code generated in 28.648583 ms
2021-11-25 13:55:22 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:55:22 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:55:22 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:62158 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:55:22 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:58
2021-11-25 13:55:22 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:55:22 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:58
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:58) with 1 output partitions
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:58)
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58), which has no missing parents
2021-11-25 13:55:22 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 13:55:22 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KB, free 912.0 MB)
2021-11-25 13:55:22 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:62158 (size: 6.3 KB, free: 912.3 MB)
2021-11-25 13:55:22 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:55:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:58) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:55:22 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:55:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:55:22 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:55:22 INFO  CodeGenerator:54 - Code generated in 172.02325 ms
2021-11-25 13:55:22 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:55:22 INFO  CodeGenerator:54 - Code generated in 56.796959 ms
2021-11-25 13:55:23 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2021-11-25 13:55:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 557 ms on localhost (executor driver) (1/1)
2021-11-25 13:55:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:55:23 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:58) finished in 0.757 s
2021-11-25 13:55:23 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:58, took 0.801467 s
2021-11-25 13:55:23 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:55:23 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:55:23 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:55:23 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:55:23 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:55:23 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:55:23 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:55:23 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:55:23 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:55:23 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:55:23 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-26b80c74-07ab-46ef-9058-f3e0168847bc
2021-11-25 13:55:40 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 13:55:46 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 13:55:46 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 13:55:46 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 13:55:47 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 13:55:47 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 13:55:47 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 13:55:47 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 13:55:47 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 13:55:52 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62208.
2021-11-25 13:55:52 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 13:55:52 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 13:55:52 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 13:55:52 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 13:55:52 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-69228b6a-0130-402f-8c74-7300a8335fc9
2021-11-25 13:55:52 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 13:55:52 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 13:55:52 INFO  log:192 - Logging initialized @11957ms
2021-11-25 13:55:52 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 13:55:52 INFO  Server:419 - Started @12009ms
2021-11-25 13:55:52 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:55:52 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 13:55:52 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.17:4040
2021-11-25 13:55:52 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 13:55:52 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62209.
2021-11-25 13:55:52 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.17:62209
2021-11-25 13:55:52 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 13:55:52 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.17, 62209, None)
2021-11-25 13:55:52 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.17:62209 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.17, 62209, None)
2021-11-25 13:55:52 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.17, 62209, None)
2021-11-25 13:55:52 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.17, 62209, None)
2021-11-25 13:55:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 13:55:53 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 13:55:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 13:55:53 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 13:55:55 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 13:55:55 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 13:55:55 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 13:55:55 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 13:55:55 INFO  CodeGenerator:54 - Code generated in 208.421541 ms
2021-11-25 13:55:56 INFO  CodeGenerator:54 - Code generated in 31.149917 ms
2021-11-25 13:55:56 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 13:55:56 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 13:55:56 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.17:62209 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 13:55:56 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:56
2021-11-25 13:55:56 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 13:55:56 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:56
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:56) with 1 output partitions
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:56)
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:56), which has no missing parents
2021-11-25 13:55:56 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.0 MB)
2021-11-25 13:55:56 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.0 MB)
2021-11-25 13:55:56 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.17:62209 (size: 3.7 KB, free: 912.3 MB)
2021-11-25 13:55:56 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 13:55:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:56) (first 15 tasks are for partitions Vector(0))
2021-11-25 13:55:56 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 13:55:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 13:55:56 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 13:55:56 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-7672, partition values: [empty row]
2021-11-25 13:55:56 INFO  CodeGenerator:54 - Code generated in 31.157708 ms
2021-11-25 13:55:56 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1575 bytes result sent to driver
2021-11-25 13:55:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 247 ms on localhost (executor driver) (1/1)
2021-11-25 13:55:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 13:55:57 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:56) finished in 0.369 s
2021-11-25 13:55:57 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:56, took 0.412058 s
2021-11-25 13:55:57 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 13:55:57 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 13:55:57 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.17:4040
2021-11-25 13:55:57 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 13:55:57 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 13:55:57 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 13:55:57 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 13:55:57 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 13:55:57 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 13:55:57 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 13:55:57 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-da24489f-bc29-4858-ac94-221d3b4f9c0e
2021-11-25 14:03:35 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:03:40 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:03:41 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:03:41 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:03:41 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:03:41 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:03:41 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:03:41 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:03:41 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:03:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62879.
2021-11-25 14:03:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:03:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:03:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:03:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:03:46 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-e575e7be-b221-442f-a093-9b7de34c5595
2021-11-25 14:03:46 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:03:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:03:47 INFO  log:192 - Logging initialized @12222ms
2021-11-25 14:03:47 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:03:47 INFO  Server:419 - Started @12282ms
2021-11-25 14:03:47 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:03:47 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:03:47 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:03:47 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62880.
2021-11-25 14:03:47 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:62880
2021-11-25 14:03:47 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:03:47 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 62880, None)
2021-11-25 14:03:47 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:62880 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 62880, None)
2021-11-25 14:03:47 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 62880, None)
2021-11-25 14:03:47 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 62880, None)
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:03:47 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:03:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:03:48 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:03:50 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:03:50 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:03:50 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:03:50 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:03:51 INFO  CodeGenerator:54 - Code generated in 297.876334 ms
2021-11-25 14:03:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:03:51 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:03:51 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:62880 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:03:51 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:42
2021-11-25 14:03:51 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:03:52 INFO  SparkContext:54 - Starting job: json at WriteToS3.scala:42
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Got job 0 (json at WriteToS3.scala:42) with 1 output partitions
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (json at WriteToS3.scala:42)
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at WriteToS3.scala:42), which has no missing parents
2021-11-25 14:03:52 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.6 KB, free 912.0 MB)
2021-11-25 14:03:52 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 14:03:52 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:62880 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 14:03:52 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at WriteToS3.scala:42) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:03:52 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:03:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8352 bytes)
2021-11-25 14:03:52 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:03:52 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.json, range: 0-7672, partition values: [empty row]
2021-11-25 14:03:52 INFO  CodeGenerator:54 - Code generated in 84.04325 ms
2021-11-25 14:03:52 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1893 bytes result sent to driver
2021-11-25 14:03:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 431 ms on localhost (executor driver) (1/1)
2021-11-25 14:03:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:03:52 INFO  DAGScheduler:54 - ResultStage 0 (json at WriteToS3.scala:42) finished in 0.526 s
2021-11-25 14:03:52 INFO  DAGScheduler:54 - Job 0 finished: json at WriteToS3.scala:42, took 0.573027 s
2021-11-25 14:03:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:03:52 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:03:52 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:03:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:03:52 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:03:52 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:03:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:03:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:03:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:03:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:03:52 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-bf25e6e0-3e9b-456b-82bc-38f042451000
2021-11-25 14:04:50 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:04:55 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:04:56 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:04:56 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:04:56 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:04:56 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:04:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:04:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:04:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:05:01 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 62983.
2021-11-25 14:05:01 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:05:01 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:05:01 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:05:01 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:05:01 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-fac75621-15c4-4e4a-bef7-87b4e3d072d9
2021-11-25 14:05:01 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:05:01 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:05:01 INFO  log:192 - Logging initialized @11920ms
2021-11-25 14:05:01 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:05:01 INFO  Server:419 - Started @11968ms
2021-11-25 14:05:01 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:05:01 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:05:01 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:05:02 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:05:02 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62984.
2021-11-25 14:05:02 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:62984
2021-11-25 14:05:02 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:05:02 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 62984, None)
2021-11-25 14:05:02 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:62984 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 62984, None)
2021-11-25 14:05:02 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 62984, None)
2021-11-25 14:05:02 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 62984, None)
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:05:02 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:05:02 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:05:05 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:05:05 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:05:05 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:05:05 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:05:06 INFO  CodeGenerator:54 - Code generated in 316.042583 ms
2021-11-25 14:05:06 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:05:06 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:05:06 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:62984 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:05:06 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:42
2021-11-25 14:05:06 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4201976 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:05:06 INFO  SparkContext:54 - Starting job: json at WriteToS3.scala:42
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Got job 0 (json at WriteToS3.scala:42) with 1 output partitions
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (json at WriteToS3.scala:42)
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at WriteToS3.scala:42), which has no missing parents
2021-11-25 14:05:06 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.6 KB, free 912.0 MB)
2021-11-25 14:05:06 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 14:05:06 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:62984 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 14:05:06 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at WriteToS3.scala:42) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:05:06 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:05:06 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8352 bytes)
2021-11-25 14:05:06 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:05:06 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.json, range: 0-7672, partition values: [empty row]
2021-11-25 14:05:06 INFO  CodeGenerator:54 - Code generated in 42.530792 ms
2021-11-25 14:05:06 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1893 bytes result sent to driver
2021-11-25 14:05:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 337 ms on localhost (executor driver) (1/1)
2021-11-25 14:05:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:05:06 INFO  DAGScheduler:54 - ResultStage 0 (json at WriteToS3.scala:42) finished in 0.427 s
2021-11-25 14:05:06 INFO  DAGScheduler:54 - Job 0 finished: json at WriteToS3.scala:42, took 0.473923 s
2021-11-25 14:05:06 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:05:06 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:05:06 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:05:06 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:05:07 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:05:07 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:05:07 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:05:07 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:05:07 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:05:07 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:05:07 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-60170a84-aa30-497e-b742-68620a4ccc2c
2021-11-25 14:07:34 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:07:40 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:07:40 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:07:40 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:07:40 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:07:40 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:07:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:07:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:07:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:07:46 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63201.
2021-11-25 14:07:46 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:07:46 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:07:46 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:07:46 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:07:46 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-820e0fc4-7288-4c3b-a08a-e2e78839a169
2021-11-25 14:07:46 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:07:46 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:07:46 INFO  log:192 - Logging initialized @11991ms
2021-11-25 14:07:46 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:07:46 INFO  Server:419 - Started @12039ms
2021-11-25 14:07:46 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:07:46 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:07:46 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:07:46 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:07:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63202.
2021-11-25 14:07:46 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63202
2021-11-25 14:07:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:07:46 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63202, None)
2021-11-25 14:07:46 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63202 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63202, None)
2021-11-25 14:07:46 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63202, None)
2021-11-25 14:07:46 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63202, None)
2021-11-25 14:07:46 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:07:47 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:07:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:07:47 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:07:47 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:07:48 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:07:48 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63202 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:07:48 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:43
2021-11-25 14:07:48 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:07:48 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:07:48 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:07:48 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:07:48 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:07:48 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:07:48 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:07:48 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:07:48 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:07:48 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:07:48 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-ddc7835b-610b-4418-944f-59260a3e1312
2021-11-25 14:09:35 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:09:45 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:09:50 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:09:51 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:09:51 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:09:51 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:09:51 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:09:51 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:09:51 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:09:51 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:09:56 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63382.
2021-11-25 14:09:56 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:09:56 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:09:56 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:09:56 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:09:56 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-02a53a71-99ba-496e-ada0-e8c3f5a29948
2021-11-25 14:09:56 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:09:56 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:09:56 INFO  log:192 - Logging initialized @12091ms
2021-11-25 14:09:56 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:09:56 INFO  Server:419 - Started @12147ms
2021-11-25 14:09:56 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:09:56 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:09:56 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:09:57 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:09:57 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63383.
2021-11-25 14:09:57 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63383
2021-11-25 14:09:57 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:09:57 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63383, None)
2021-11-25 14:09:57 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63383 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63383, None)
2021-11-25 14:09:57 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63383, None)
2021-11-25 14:09:57 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63383, None)
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:57 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:09:57 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:09:57 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:09:58 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:09:58 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:09:58 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:09:58 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63383 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:09:58 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:43
2021-11-25 14:09:59 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:09:59 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:09:59 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:09:59 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:09:59 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:09:59 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:09:59 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:09:59 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:09:59 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:09:59 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:09:59 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-80deec6c-9c39-4412-8d80-d97c15047a10
2021-11-25 14:12:28 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:12:34 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:12:34 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:12:34 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:12:34 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:12:34 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:12:34 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:12:34 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:12:34 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:12:40 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63630.
2021-11-25 14:12:40 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:12:40 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:12:40 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:12:40 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:12:40 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-522a45b1-92fe-48f4-ad71-e22e629ffe2c
2021-11-25 14:12:40 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:12:40 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:12:40 INFO  log:192 - Logging initialized @12037ms
2021-11-25 14:12:40 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:12:40 INFO  Server:419 - Started @12086ms
2021-11-25 14:12:40 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:12:40 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:12:40 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:12:40 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63631.
2021-11-25 14:12:40 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63631
2021-11-25 14:12:40 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:12:40 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63631, None)
2021-11-25 14:12:40 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63631 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63631, None)
2021-11-25 14:12:40 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63631, None)
2021-11-25 14:12:40 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63631, None)
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:12:40 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:12:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:12:41 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:12:41 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 257.7 KB, free 912.0 MB)
2021-11-25 14:12:42 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.3 KB, free 912.0 MB)
2021-11-25 14:12:42 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63631 (size: 21.3 KB, free: 912.3 MB)
2021-11-25 14:12:42 INFO  SparkContext:54 - Created broadcast 0 from wholeTextFiles at WriteToS3.scala:43
2021-11-25 14:12:44 INFO  CodeGenerator:54 - Code generated in 278.195875 ms
2021-11-25 14:12:45 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:12:45 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:12:45 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:12:45 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:12:45 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:12:45 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:12:45 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:12:45 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:12:45 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:12:45 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:12:45 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-128b02ee-397f-4ad7-a455-0304bfb6a50b
2021-11-25 14:13:42 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:13:47 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:13:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:13:48 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:13:48 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:13:48 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:13:48 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:13:48 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:13:48 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:13:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63788.
2021-11-25 14:13:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:13:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:13:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:13:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:13:53 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-0ec706f5-98ed-4339-8156-3a6094e1bc23
2021-11-25 14:13:53 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:13:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:13:53 INFO  log:192 - Logging initialized @12543ms
2021-11-25 14:13:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:13:53 INFO  Server:419 - Started @12596ms
2021-11-25 14:13:53 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:13:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:13:54 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:13:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63789.
2021-11-25 14:13:54 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63789
2021-11-25 14:13:54 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:13:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63789, None)
2021-11-25 14:13:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63789 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63789, None)
2021-11-25 14:13:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63789, None)
2021-11-25 14:13:54 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63789, None)
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:13:54 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:13:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:13:55 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:13:55 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:13:56 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:13:56 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63789 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:13:56 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:43
2021-11-25 14:13:56 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:13:56 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:13:56 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:13:56 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:13:56 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:13:56 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:13:56 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:13:56 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:13:56 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:13:56 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:13:56 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-89fb3a05-274a-456e-826e-d1a9f9d6f6ad
2021-11-25 14:14:32 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:14:38 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:14:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:14:38 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:14:38 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:14:38 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:14:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:14:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:14:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:14:44 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63866.
2021-11-25 14:14:44 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:14:44 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:14:44 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:14:44 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:14:44 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-77239cde-d885-49c1-99dd-9224a37caa6e
2021-11-25 14:14:44 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:14:44 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:14:44 INFO  log:192 - Logging initialized @11999ms
2021-11-25 14:14:44 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:14:44 INFO  Server:419 - Started @12052ms
2021-11-25 14:14:44 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:14:44 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:14:44 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:14:44 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:14:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63873.
2021-11-25 14:14:44 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63873
2021-11-25 14:14:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:14:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63873, None)
2021-11-25 14:14:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63873 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63873, None)
2021-11-25 14:14:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63873, None)
2021-11-25 14:14:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63873, None)
2021-11-25 14:14:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:14:45 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:14:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:14:45 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:14:46 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:14:46 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:14:46 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63873 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:14:46 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:43
2021-11-25 14:14:46 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:14:46 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:14:46 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:14:46 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:14:46 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:14:46 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:14:46 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:14:46 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:14:46 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:14:46 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:14:46 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-f288d3ff-35dc-411a-9fe9-cfea90066121
2021-11-25 14:15:48 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:15:54 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:15:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:15:54 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:15:54 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:15:54 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:15:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:15:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:15:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:16:00 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 63976.
2021-11-25 14:16:00 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:16:00 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:16:00 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:16:00 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:16:00 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-438465b9-13ee-49f5-9aae-795ed387884c
2021-11-25 14:16:00 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:16:00 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:16:00 INFO  log:192 - Logging initialized @11954ms
2021-11-25 14:16:00 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:16:00 INFO  Server:419 - Started @12008ms
2021-11-25 14:16:00 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:16:00 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:16:00 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:16:00 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63978.
2021-11-25 14:16:00 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:63978
2021-11-25 14:16:00 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:16:00 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 63978, None)
2021-11-25 14:16:00 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:63978 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 63978, None)
2021-11-25 14:16:00 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 63978, None)
2021-11-25 14:16:00 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 63978, None)
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:16:00 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:16:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:16:01 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:16:01 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:16:02 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:16:02 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:63978 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:16:02 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:43
2021-11-25 14:16:02 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:16:02 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:16:02 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:16:02 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:16:02 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:16:02 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:16:02 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:16:02 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:16:02 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:16:02 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:16:02 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-974249e2-0261-4358-b5a7-974d890c5c23
2021-11-25 14:17:42 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:17:47 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:17:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:17:48 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:17:48 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:17:48 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:17:48 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:17:48 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:17:48 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:17:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64121.
2021-11-25 14:17:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:17:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:17:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:17:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:17:53 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-f290892d-7d64-48c8-bde1-1deb81121683
2021-11-25 14:17:53 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:17:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:17:53 INFO  log:192 - Logging initialized @11878ms
2021-11-25 14:17:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:17:53 INFO  Server:419 - Started @11925ms
2021-11-25 14:17:53 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:17:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:17:54 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:17:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64122.
2021-11-25 14:17:54 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64122
2021-11-25 14:17:54 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:17:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64122, None)
2021-11-25 14:17:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64122 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64122, None)
2021-11-25 14:17:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64122, None)
2021-11-25 14:17:54 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64122, None)
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:17:54 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@56781d96{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5173200b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69b2f8e5{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6331250e{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c2327fa{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:17:55 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:17:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:17:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:17:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:17:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:17:58 INFO  CodeGenerator:54 - Code generated in 207.089958 ms
2021-11-25 14:17:58 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:17:58 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:17:58 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:64122 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:17:58 INFO  SparkContext:54 - Created broadcast 0 from sql at WriteToS3.scala:42
2021-11-25 14:17:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8403952 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:17:58 INFO  SparkContext:54 - Starting job: sql at WriteToS3.scala:42
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Got job 0 (sql at WriteToS3.scala:42) with 1 output partitions
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (sql at WriteToS3.scala:42)
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at sql at WriteToS3.scala:42), which has no missing parents
2021-11-25 14:17:58 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.6 KB, free 912.0 MB)
2021-11-25 14:17:58 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 14:17:58 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:64122 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 14:17:58 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:17:58 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at sql at WriteToS3.scala:42) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:17:58 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:17:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8384 bytes)
2021-11-25 14:17:59 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:17:59 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.json, range: 0-7672, partition values: [empty row]
2021-11-25 14:17:59 INFO  CodeGenerator:54 - Code generated in 43.118084 ms
2021-11-25 14:17:59 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.json, range: 0-7672, partition values: [empty row]
2021-11-25 14:17:59 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1893 bytes result sent to driver
2021-11-25 14:17:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 370 ms on localhost (executor driver) (1/1)
2021-11-25 14:17:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:17:59 INFO  DAGScheduler:54 - ResultStage 0 (sql at WriteToS3.scala:42) finished in 0.472 s
2021-11-25 14:17:59 INFO  DAGScheduler:54 - Job 0 finished: sql at WriteToS3.scala:42, took 0.521422 s
2021-11-25 14:17:59 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:17:59 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:17:59 INFO  FileSourceStrategy:54 - Output Data Schema: struct<_corrupt_record: string>
2021-11-25 14:17:59 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:17:59 INFO  CodeGenerator:54 - Code generated in 45.296583 ms
2021-11-25 14:17:59 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 251.1 KB, free 911.8 MB)
2021-11-25 14:17:59 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 21.5 KB, free 911.8 MB)
2021-11-25 14:17:59 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 192.168.1.3:64122 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:17:59 INFO  SparkContext:54 - Created broadcast 2 from show at WriteToS3.scala:45
2021-11-25 14:17:59 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:17:59 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:17:59 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:17:59 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:17:59 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:17:59 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:17:59 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:17:59 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:17:59 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:17:59 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:17:59 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-c7391dd5-762c-448f-8e19-67bc36fb9086
2021-11-25 14:21:11 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:21:16 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:21:17 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:21:17 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:21:17 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:21:17 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:21:17 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:21:17 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:21:17 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:21:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64394.
2021-11-25 14:21:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:21:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:21:22 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:21:22 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:21:22 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-130d18ab-c357-4799-b644-6a213abf427e
2021-11-25 14:21:22 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:21:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:21:22 INFO  log:192 - Logging initialized @11948ms
2021-11-25 14:21:22 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:21:22 INFO  Server:419 - Started @11994ms
2021-11-25 14:21:22 INFO  AbstractConnector:278 - Started ServerConnector@2c8331bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:21:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74cec793{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a82f33{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:21:22 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/static,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/api,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:21:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:21:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64395.
2021-11-25 14:21:23 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64395
2021-11-25 14:21:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:21:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64395, None)
2021-11-25 14:21:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64395 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64395, None)
2021-11-25 14:21:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64395, None)
2021-11-25 14:21:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64395, None)
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32639b12{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:21:23 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c2327fa{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3605c4d3{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ff57625{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:21:23 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:21:24 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.8 KB, free 912.1 MB)
2021-11-25 14:21:24 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:21:24 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:64395 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:21:24 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:61
2021-11-25 14:21:24 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:21:24 INFO  AbstractConnector:318 - Stopped Spark@2c8331bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:21:24 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:21:24 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:21:24 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:21:24 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:21:24 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:21:24 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:21:24 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:21:24 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:21:24 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-86aafbe7-a226-446c-ae64-ae14f4ff71af
2021-11-25 14:21:49 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:21:55 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:21:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:21:55 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:21:55 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:21:55 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:21:55 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:21:55 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:21:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:22:05 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:22:11 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:22:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:22:11 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:22:11 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:22:11 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:22:11 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:22:11 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:22:11 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:22:16 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64477.
2021-11-25 14:22:16 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:22:16 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:22:16 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:22:16 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:22:16 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-3c9aa4e1-f9eb-40bb-a235-5747e6e0e8b8
2021-11-25 14:22:16 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:22:17 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:22:17 INFO  log:192 - Logging initialized @11928ms
2021-11-25 14:22:17 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:22:17 INFO  Server:419 - Started @11977ms
2021-11-25 14:22:17 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:22:17 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:22:17 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:22:17 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64478.
2021-11-25 14:22:17 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64478
2021-11-25 14:22:17 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:22:17 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64478, None)
2021-11-25 14:22:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64478 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64478, None)
2021-11-25 14:22:17 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64478, None)
2021-11-25 14:22:17 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64478, None)
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:22:17 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:22:17 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:22:18 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:22:18 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.7 KB, free 912.1 MB)
2021-11-25 14:22:18 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.6 KB, free 912.0 MB)
2021-11-25 14:22:18 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:64478 (size: 21.6 KB, free: 912.3 MB)
2021-11-25 14:22:18 INFO  SparkContext:54 - Created broadcast 0 from json at WriteToS3.scala:61
2021-11-25 14:22:19 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:22:19 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:22:19 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:22:19 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:22:19 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:22:19 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:22:19 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:22:19 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:22:19 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:22:19 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:22:19 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-37e0857f-9c98-465b-857c-726b3a7d4024
2021-11-25 14:24:57 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:25:03 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:25:03 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:25:03 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:25:03 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:25:03 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:25:03 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:25:03 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:25:03 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:25:09 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64704.
2021-11-25 14:25:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:25:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:25:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:25:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:25:09 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-78724168-0fc5-4619-9038-0e1e212f44cd
2021-11-25 14:25:09 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:25:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:25:09 INFO  log:192 - Logging initialized @12023ms
2021-11-25 14:25:09 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:25:09 INFO  Server:419 - Started @12075ms
2021-11-25 14:25:09 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:25:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:25:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:25:09 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:25:09 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64705.
2021-11-25 14:25:09 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64705
2021-11-25 14:25:09 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:25:09 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64705, None)
2021-11-25 14:25:09 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64705 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64705, None)
2021-11-25 14:25:09 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64705, None)
2021-11-25 14:25:09 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64705, None)
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:25:10 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:25:10 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:25:13 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:25:13 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:25:13 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:25:13 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:25:13 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:25:13 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:25:13 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:25:13 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:25:13 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:25:13 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:25:13 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-50f4772b-9eb2-4238-88cd-b570ca1391b6
2021-11-25 14:25:49 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:25:54 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:25:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:25:55 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:25:55 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:25:55 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:25:55 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:25:55 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:25:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:26:00 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64784.
2021-11-25 14:26:00 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:26:00 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:26:00 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:26:00 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:26:00 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-3a11b3cd-69a5-4aa2-b9a7-f02dd13714e5
2021-11-25 14:26:00 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:26:00 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:26:00 INFO  log:192 - Logging initialized @11937ms
2021-11-25 14:26:00 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:26:00 INFO  Server:419 - Started @11995ms
2021-11-25 14:26:00 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:26:00 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:26:00 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:26:01 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:26:01 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64785.
2021-11-25 14:26:01 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64785
2021-11-25 14:26:01 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:26:01 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64785, None)
2021-11-25 14:26:01 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64785 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64785, None)
2021-11-25 14:26:01 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64785, None)
2021-11-25 14:26:01 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64785, None)
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:26:01 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:26:01 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:26:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:26:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:26:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:26:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:26:04 INFO  CodeGenerator:54 - Code generated in 228.507458 ms
2021-11-25 14:26:05 INFO  CodeGenerator:54 - Code generated in 38.962041 ms
2021-11-25 14:26:05 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:26:05 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:26:05 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:64785 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:26:05 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:64
2021-11-25 14:26:05 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:26:05 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:64
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:64) with 1 output partitions
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:64)
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:64), which has no missing parents
2021-11-25 14:26:05 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 912.0 MB)
2021-11-25 14:26:05 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.0 MB)
2021-11-25 14:26:05 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:64785 (size: 3.7 KB, free: 912.3 MB)
2021-11-25 14:26:05 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at WriteToS3.scala:64) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:26:05 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:26:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 14:26:05 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:26:05 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 14:26:05 INFO  CodeGenerator:54 - Code generated in 31.424541 ms
2021-11-25 14:26:05 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2337 bytes result sent to driver
2021-11-25 14:26:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 238 ms on localhost (executor driver) (1/1)
2021-11-25 14:26:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:26:05 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:64) finished in 0.366 s
2021-11-25 14:26:05 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:64, took 0.399773 s
2021-11-25 14:26:05 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:26:05 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:26:05 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:26:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:26:05 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:26:05 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:26:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:26:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:26:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:26:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:26:05 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-b10cb062-5b64-4dc4-b703-bdb1664891ab
2021-11-25 14:27:37 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:27:42 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:27:42 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:27:42 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:27:43 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:27:43 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:27:43 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:27:43 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:27:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:27:48 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64928.
2021-11-25 14:27:48 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:27:48 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:27:48 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:27:48 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:27:48 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-8c0620ca-ef71-49ed-a371-125ade982089
2021-11-25 14:27:48 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:27:48 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:27:48 INFO  log:192 - Logging initialized @11962ms
2021-11-25 14:27:48 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:27:48 INFO  Server:419 - Started @12010ms
2021-11-25 14:27:48 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:27:48 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:27:48 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:27:48 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:27:48 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64929.
2021-11-25 14:27:48 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64929
2021-11-25 14:27:48 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:27:48 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64929, None)
2021-11-25 14:27:48 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64929 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64929, None)
2021-11-25 14:27:48 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64929, None)
2021-11-25 14:27:48 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64929, None)
2021-11-25 14:27:48 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:27:49 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:27:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:27:49 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:27:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:27:52 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:27:52 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:27:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:27:52 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:27:52 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:27:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:27:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:27:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:27:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:27:52 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-f219953c-1c2a-4386-9a23-ac718bb1dafd
2021-11-25 14:28:22 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:28:28 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:28:28 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:28:28 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:28:28 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:28:28 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:28:28 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:28:28 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:28:28 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:28:34 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 64996.
2021-11-25 14:28:34 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:28:34 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:28:34 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:28:34 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:28:34 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-727b43ec-7093-47f6-ad37-e43d65ffdb83
2021-11-25 14:28:34 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:28:34 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:28:34 INFO  log:192 - Logging initialized @11919ms
2021-11-25 14:28:34 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:28:34 INFO  Server:419 - Started @11966ms
2021-11-25 14:28:34 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:28:34 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:28:34 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:28:34 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:28:34 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64997.
2021-11-25 14:28:34 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:64997
2021-11-25 14:28:34 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:28:34 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 64997, None)
2021-11-25 14:28:34 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:64997 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 64997, None)
2021-11-25 14:28:34 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 64997, None)
2021-11-25 14:28:34 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 64997, None)
2021-11-25 14:28:34 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:28:35 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:28:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:28:35 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:28:37 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:28:37 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:28:37 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:28:37 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:28:37 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:28:37 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:28:37 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:28:37 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:28:37 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:28:37 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:28:37 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-9dcdbbd6-8ca6-4a7a-a384-dbb38fc12cb9
2021-11-25 14:29:12 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:29:21 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:29:26 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:29:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:29:27 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:29:27 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:29:27 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:29:27 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:29:27 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:29:27 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:29:32 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 65092.
2021-11-25 14:29:32 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:29:32 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:29:32 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:29:32 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:29:32 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-7eff016f-ee6c-4c15-9d43-0f00f101a037
2021-11-25 14:29:32 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:29:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:29:33 INFO  log:192 - Logging initialized @12253ms
2021-11-25 14:29:33 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:29:33 INFO  Server:419 - Started @12306ms
2021-11-25 14:29:33 INFO  AbstractConnector:278 - Started ServerConnector@714fc079{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:29:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74cec793{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a82f33{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/static,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/api,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:29:33 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:29:33 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65093.
2021-11-25 14:29:33 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:65093
2021-11-25 14:29:33 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:29:33 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 65093, None)
2021-11-25 14:29:33 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:65093 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 65093, None)
2021-11-25 14:29:33 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 65093, None)
2021-11-25 14:29:33 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 65093, None)
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32639b12{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:29:33 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d7fa3ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a6b94{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:29:33 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8326a4{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:29:34 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:29:37 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:29:37 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:29:37 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:29:37 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:29:37 INFO  CodeGenerator:54 - Code generated in 353.143042 ms
2021-11-25 14:29:38 INFO  CodeGenerator:54 - Code generated in 32.249709 ms
2021-11-25 14:29:38 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:29:38 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:29:38 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:65093 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:29:38 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:65
2021-11-25 14:29:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:29:38 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:65
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:65) with 1 output partitions
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:65)
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:65), which has no missing parents
2021-11-25 14:29:38 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 14:29:38 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 14:29:38 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:65093 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 14:29:38 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:65) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:29:38 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:29:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 14:29:38 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:29:38 INFO  CodeGenerator:54 - Code generated in 31.224541 ms
2021-11-25 14:29:38 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 14:29:38 INFO  CodeGenerator:54 - Code generated in 24.983208 ms
2021-11-25 14:29:38 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2619 bytes result sent to driver
2021-11-25 14:29:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 339 ms on localhost (executor driver) (1/1)
2021-11-25 14:29:38 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:29:38 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:65) finished in 0.504 s
2021-11-25 14:29:38 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:65, took 0.548781 s
2021-11-25 14:29:38 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:29:38 INFO  AbstractConnector:318 - Stopped Spark@714fc079{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:29:39 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:29:39 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:29:39 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:29:39 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:29:39 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:29:39 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:29:39 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:29:39 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:29:39 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-47b62232-f914-4533-b1b0-6d87387cb9f5
2021-11-25 14:31:54 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 14:32:00 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 14:32:00 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 14:32:00 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 14:32:00 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 14:32:00 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 14:32:00 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 14:32:00 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 14:32:00 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 14:32:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 65296.
2021-11-25 14:32:06 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 14:32:06 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 14:32:06 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 14:32:06 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 14:32:06 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-e4366dd2-cd8a-4251-8bdb-0522016d5d2c
2021-11-25 14:32:06 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 14:32:06 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 14:32:06 INFO  log:192 - Logging initialized @12132ms
2021-11-25 14:32:06 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 14:32:06 INFO  Server:419 - Started @12184ms
2021-11-25 14:32:06 INFO  AbstractConnector:278 - Started ServerConnector@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:32:06 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fefce9e{/jobs,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6bab2585{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@611f8234{/stages,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cbee484{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4089713{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b91d8c4{/storage,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6166aa{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a77614d{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a067c25{/environment,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1217f9{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bde62ff{/executors,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523424b5{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/static,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/api,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@142eef62{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 14:32:06 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 14:32:06 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 14:32:06 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65297.
2021-11-25 14:32:06 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:65297
2021-11-25 14:32:06 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 14:32:06 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 65297, None)
2021-11-25 14:32:06 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:65297 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 65297, None)
2021-11-25 14:32:06 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 65297, None)
2021-11-25 14:32:06 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 65297, None)
2021-11-25 14:32:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20d11153{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 14:32:07 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 14:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d847d32{/SQL,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f462e3b{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@585c13de{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@187eb9a8{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ee29c84{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 14:32:07 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 14:32:10 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 14:32:10 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 14:32:10 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 14:32:10 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 14:32:11 INFO  CodeGenerator:54 - Code generated in 351.788792 ms
2021-11-25 14:32:11 INFO  CodeGenerator:54 - Code generated in 26.548667 ms
2021-11-25 14:32:11 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 14:32:11 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 14:32:11 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:65297 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 14:32:11 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:68
2021-11-25 14:32:11 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 14:32:11 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:68
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:68) with 1 output partitions
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:68)
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:68), which has no missing parents
2021-11-25 14:32:11 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.5 KB, free 912.0 MB)
2021-11-25 14:32:11 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 912.0 MB)
2021-11-25 14:32:11 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:65297 (size: 5.5 KB, free: 912.3 MB)
2021-11-25 14:32:11 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 14:32:11 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:68) (first 15 tasks are for partitions Vector(0))
2021-11-25 14:32:11 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 14:32:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 14:32:11 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 14:32:12 INFO  CodeGenerator:54 - Code generated in 46.649375 ms
2021-11-25 14:32:12 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 14:32:12 INFO  CodeGenerator:54 - Code generated in 28.270541 ms
2021-11-25 14:32:12 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2658 bytes result sent to driver
2021-11-25 14:32:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 372 ms on localhost (executor driver) (1/1)
2021-11-25 14:32:12 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 14:32:12 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:68) finished in 0.535 s
2021-11-25 14:32:12 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:68, took 0.573983 s
2021-11-25 14:32:12 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 14:32:12 INFO  AbstractConnector:318 - Stopped Spark@7f69d591{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 14:32:12 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 14:32:12 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 14:32:12 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 14:32:12 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 14:32:12 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 14:32:12 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 14:32:12 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 14:32:12 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 14:32:12 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-711b0ee1-34e4-4eb3-b698-4d50f807cab9
2021-11-25 16:10:39 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 16:10:44 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 16:10:45 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 16:10:45 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 16:10:45 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 16:10:45 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 16:10:45 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 16:10:45 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 16:10:45 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 16:10:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 50625.
2021-11-25 16:10:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 16:10:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 16:10:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 16:10:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 16:10:50 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-51609fe6-8931-4a85-b7c1-c1660513be22
2021-11-25 16:10:50 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 16:10:51 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 16:10:51 INFO  log:192 - Logging initialized @12245ms
2021-11-25 16:10:51 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 16:10:51 INFO  Server:419 - Started @12299ms
2021-11-25 16:10:51 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:10:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 16:10:51 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 16:10:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50626.
2021-11-25 16:10:51 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:50626
2021-11-25 16:10:51 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 16:10:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 50626, None)
2021-11-25 16:10:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:50626 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 50626, None)
2021-11-25 16:10:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 50626, None)
2021-11-25 16:10:51 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 50626, None)
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 16:10:51 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60baef24{/SQL,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad5923a{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4463d9d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 16:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13d186db{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 16:10:52 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 16:10:55 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 16:10:55 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 16:10:55 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 16:10:55 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 16:10:56 INFO  CodeGenerator:54 - Code generated in 407.258542 ms
2021-11-25 16:10:56 INFO  CodeGenerator:54 - Code generated in 32.315083 ms
2021-11-25 16:10:56 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 16:10:57 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 16:10:57 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:50626 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 16:10:57 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:83
2021-11-25 16:10:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 16:10:57 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:83
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:83) with 1 output partitions
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:83)
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:83), which has no missing parents
2021-11-25 16:10:57 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.9 KB, free 912.0 MB)
2021-11-25 16:10:57 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 16:10:57 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:50626 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 16:10:57 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 16:10:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:83) (first 15 tasks are for partitions Vector(0))
2021-11-25 16:10:57 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 16:10:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 16:10:57 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 16:10:57 INFO  CodeGenerator:54 - Code generated in 182.864875 ms
2021-11-25 16:10:57 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 16:10:57 INFO  CodeGenerator:54 - Code generated in 42.67225 ms
2021-11-25 16:10:58 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2444 bytes result sent to driver
2021-11-25 16:10:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 589 ms on localhost (executor driver) (1/1)
2021-11-25 16:10:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 16:10:58 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:83) finished in 0.841 s
2021-11-25 16:10:58 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:83, took 0.883903 s
2021-11-25 16:10:58 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 16:10:58 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:10:58 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 16:10:58 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 16:10:58 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 16:10:58 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 16:10:58 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 16:10:58 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 16:10:58 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 16:10:58 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 16:10:58 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-902643ba-9945-47c4-bf50-daeb280dd0bb
2021-11-25 16:12:17 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 16:12:22 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 16:12:23 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 16:12:23 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 16:12:23 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 16:12:23 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 16:12:23 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 16:12:23 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 16:12:23 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 16:12:28 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 50749.
2021-11-25 16:12:28 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 16:12:28 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 16:12:28 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 16:12:28 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 16:12:28 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-fe241215-18a0-4bb0-a133-9e5ed9ffb460
2021-11-25 16:12:28 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 16:12:28 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 16:12:28 INFO  log:192 - Logging initialized @11966ms
2021-11-25 16:12:28 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 16:12:28 INFO  Server:419 - Started @12014ms
2021-11-25 16:12:28 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:12:28 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 16:12:28 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 16:12:29 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 16:12:29 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50750.
2021-11-25 16:12:29 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:50750
2021-11-25 16:12:29 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 16:12:29 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 50750, None)
2021-11-25 16:12:29 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:50750 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 50750, None)
2021-11-25 16:12:29 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 50750, None)
2021-11-25 16:12:29 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 50750, None)
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 16:12:29 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60baef24{/SQL,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61533ae{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ad5923a{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4463d9d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13d186db{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 16:12:29 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 16:12:33 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 16:12:33 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 16:12:33 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 16:12:33 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 16:12:33 INFO  CodeGenerator:54 - Code generated in 337.425959 ms
2021-11-25 16:12:34 INFO  CodeGenerator:54 - Code generated in 28.048 ms
2021-11-25 16:12:34 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 16:12:34 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 16:12:34 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:50750 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 16:12:34 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:84
2021-11-25 16:12:34 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 16:12:34 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:84
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:84) with 1 output partitions
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:84)
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:84), which has no missing parents
2021-11-25 16:12:34 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 12.7 KB, free 912.0 MB)
2021-11-25 16:12:34 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 912.0 MB)
2021-11-25 16:12:34 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:50750 (size: 6.4 KB, free: 912.3 MB)
2021-11-25 16:12:34 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 16:12:34 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:84) (first 15 tasks are for partitions Vector(0))
2021-11-25 16:12:34 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 16:12:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 16:12:34 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 16:12:34 INFO  CodeGenerator:54 - Code generated in 140.861875 ms
2021-11-25 16:12:34 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 16:12:34 INFO  CodeGenerator:54 - Code generated in 53.430625 ms
2021-11-25 16:12:35 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2471 bytes result sent to driver
2021-11-25 16:12:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 530 ms on localhost (executor driver) (1/1)
2021-11-25 16:12:35 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 16:12:35 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:84) finished in 0.735 s
2021-11-25 16:12:35 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:84, took 0.777194 s
2021-11-25 16:12:35 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 16:12:35 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:12:35 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 16:12:35 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 16:12:35 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 16:12:35 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 16:12:35 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 16:12:35 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 16:12:35 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 16:12:35 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 16:12:35 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-d5a7c1e1-70ed-4755-a6b9-dc82ceae0163
2021-11-25 16:15:42 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 16:15:47 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 16:15:47 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 16:15:48 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 16:15:48 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 16:15:48 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 16:15:48 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 16:15:48 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 16:15:48 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 16:15:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 51013.
2021-11-25 16:15:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 16:15:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 16:15:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 16:15:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 16:15:53 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-c99ab03f-66af-4cde-891d-73b0e476b498
2021-11-25 16:15:53 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 16:15:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 16:15:53 INFO  log:192 - Logging initialized @12081ms
2021-11-25 16:15:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 16:15:53 INFO  Server:419 - Started @12130ms
2021-11-25 16:15:53 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:15:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 16:15:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 16:15:53 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 16:15:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51014.
2021-11-25 16:15:53 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:51014
2021-11-25 16:15:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 16:15:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 51014, None)
2021-11-25 16:15:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:51014 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 51014, None)
2021-11-25 16:15:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 51014, None)
2021-11-25 16:15:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 51014, None)
2021-11-25 16:15:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 16:15:54 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 16:15:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 16:15:54 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 16:15:57 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 16:15:57 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 16:15:57 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 16:15:57 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 16:15:58 INFO  CodeGenerator:54 - Code generated in 329.453791 ms
2021-11-25 16:15:58 INFO  CodeGenerator:54 - Code generated in 37.813542 ms
2021-11-25 16:15:58 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 16:15:58 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 16:15:58 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:51014 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 16:15:58 INFO  SparkContext:54 - Created broadcast 0 from show at WriteToS3.scala:84
2021-11-25 16:15:58 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 16:15:59 INFO  SparkContext:54 - Starting job: show at WriteToS3.scala:84
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Got job 0 (show at WriteToS3.scala:84) with 1 output partitions
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (show at WriteToS3.scala:84)
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:84), which has no missing parents
2021-11-25 16:15:59 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 912.0 MB)
2021-11-25 16:15:59 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 16:15:59 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:51014 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 16:15:59 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at show at WriteToS3.scala:84) (first 15 tasks are for partitions Vector(0))
2021-11-25 16:15:59 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 16:15:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 16:15:59 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 16:15:59 INFO  CodeGenerator:54 - Code generated in 29.686125 ms
2021-11-25 16:15:59 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 16:15:59 INFO  CodeGenerator:54 - Code generated in 27.065542 ms
2021-11-25 16:15:59 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2219 bytes result sent to driver
2021-11-25 16:15:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 334 ms on localhost (executor driver) (1/1)
2021-11-25 16:15:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 16:15:59 INFO  DAGScheduler:54 - ResultStage 0 (show at WriteToS3.scala:84) finished in 0.536 s
2021-11-25 16:15:59 INFO  DAGScheduler:54 - Job 0 finished: show at WriteToS3.scala:84, took 0.578147 s
2021-11-25 16:15:59 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 16:15:59 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:15:59 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 16:15:59 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 16:15:59 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 16:15:59 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 16:15:59 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 16:15:59 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 16:15:59 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 16:15:59 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 16:15:59 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-5702ab59-f875-4a8e-b52c-cec1fd5efa96
2021-11-25 16:33:31 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 16:33:37 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 16:33:37 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 16:33:37 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 16:33:37 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 16:33:37 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 16:33:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 16:33:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 16:33:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 16:33:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52497.
2021-11-25 16:33:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 16:33:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 16:33:43 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 16:33:43 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 16:33:43 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-0a27ef57-be0d-4b73-8c19-43b410f36079
2021-11-25 16:33:43 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 16:33:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 16:33:43 INFO  log:192 - Logging initialized @12411ms
2021-11-25 16:33:43 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 16:33:43 INFO  Server:419 - Started @12466ms
2021-11-25 16:33:43 INFO  AbstractConnector:278 - Started ServerConnector@2800e16a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:33:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a8ab068{/jobs,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2baa8d82{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a7e2d9d{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/stages,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f19b8b3{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/storage,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/environment,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/executors,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/static,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64da2a7{/,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/api,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b9d6699{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 16:33:43 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 16:33:43 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 16:33:43 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52498.
2021-11-25 16:33:43 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:52498
2021-11-25 16:33:43 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 16:33:43 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 52498, None)
2021-11-25 16:33:43 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:52498 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 52498, None)
2021-11-25 16:33:43 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 52498, None)
2021-11-25 16:33:43 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 52498, None)
2021-11-25 16:33:43 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5767b2af{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 16:33:44 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 16:33:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f012914{/SQL,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@732bb66d{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5395ea39{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 16:33:44 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 16:33:48 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 16:33:48 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 16:33:48 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 16:33:48 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 16:33:48 INFO  CodeGenerator:54 - Code generated in 352.351041 ms
2021-11-25 16:33:48 INFO  CodeGenerator:54 - Code generated in 31.361291 ms
2021-11-25 16:33:49 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 16:33:49 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 16:33:49 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:52498 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 16:33:49 INFO  SparkContext:54 - Created broadcast 0 from collectAsList at WriteToS3.scala:84
2021-11-25 16:33:49 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 16:33:49 INFO  SparkContext:54 - Starting job: collectAsList at WriteToS3.scala:84
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Got job 0 (collectAsList at WriteToS3.scala:84) with 1 output partitions
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (collectAsList at WriteToS3.scala:84)
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at collectAsList at WriteToS3.scala:84), which has no missing parents
2021-11-25 16:33:49 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 912.0 MB)
2021-11-25 16:33:49 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 16:33:49 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:52498 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 16:33:49 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 16:33:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collectAsList at WriteToS3.scala:84) (first 15 tasks are for partitions Vector(0))
2021-11-25 16:33:49 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 16:33:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 16:33:49 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 16:33:49 INFO  CodeGenerator:54 - Code generated in 34.633958 ms
2021-11-25 16:33:49 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 16:33:49 INFO  CodeGenerator:54 - Code generated in 26.160042 ms
2021-11-25 16:33:50 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2398 bytes result sent to driver
2021-11-25 16:33:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 417 ms on localhost (executor driver) (1/1)
2021-11-25 16:33:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 16:33:50 INFO  DAGScheduler:54 - ResultStage 0 (collectAsList at WriteToS3.scala:84) finished in 0.519 s
2021-11-25 16:33:50 INFO  DAGScheduler:54 - Job 0 finished: collectAsList at WriteToS3.scala:84, took 0.592799 s
2021-11-25 16:33:50 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 16:33:50 INFO  AbstractConnector:318 - Stopped Spark@2800e16a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:33:50 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 16:33:50 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 16:33:50 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 16:33:50 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 16:33:50 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 16:33:50 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 16:33:50 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 16:33:50 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 16:33:50 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-e20db935-4c1c-4194-ace3-6b967cbf0e5b
2021-11-25 16:34:44 INFO  SparkInstance$:16 - Initializing spark session
2021-11-25 16:34:49 INFO  SparkContext:54 - Running Spark version 2.3.4
2021-11-25 16:34:49 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-11-25 16:34:50 INFO  SparkContext:54 - Submitted application: b2c-janiobackned-cdc
2021-11-25 16:34:50 INFO  SecurityManager:54 - Changing view acls to: tusharmudgal
2021-11-25 16:34:50 INFO  SecurityManager:54 - Changing modify acls to: tusharmudgal
2021-11-25 16:34:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-11-25 16:34:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-11-25 16:34:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tusharmudgal); groups with view permissions: Set(); users  with modify permissions: Set(tusharmudgal); groups with modify permissions: Set()
2021-11-25 16:34:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52607.
2021-11-25 16:34:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-11-25 16:34:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-11-25 16:34:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-11-25 16:34:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-11-25 16:34:55 INFO  DiskBlockManager:54 - Created local directory at /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/blockmgr-7c78ac7f-0bd1-4f4f-85ef-d9277bb321e8
2021-11-25 16:34:55 INFO  MemoryStore:54 - MemoryStore started with capacity 912.3 MB
2021-11-25 16:34:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-11-25 16:34:55 INFO  log:192 - Logging initialized @12050ms
2021-11-25 16:34:55 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-11-25 16:34:55 INFO  Server:419 - Started @12096ms
2021-11-25 16:34:55 INFO  AbstractConnector:278 - Started ServerConnector@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:34:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1922e6d{/jobs,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@319dead1{/jobs/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@791cbf87{/jobs/job,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@754777cd{/jobs/job/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/stages,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372ea2bc{/stages/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc76301{/stages/stage,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7de0c6ae{/stages/stage/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a486d78{/stages/pool,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cdc3aae{/stages/pool/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/storage,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dcbb60{/storage/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c36250e{/storage/rdd,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21526f6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49f5c307{/environment,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@299266e2{/environment/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5471388b{/executors,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66ea1466{/executors/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1601e47{/executors/threadDump,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bffddff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66971f6b{/static,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46074492{/,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d78795{/api,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7caa550{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21694e53{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-11-25 16:34:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
2021-11-25 16:34:55 INFO  Executor:54 - Starting executor ID driver on host localhost
2021-11-25 16:34:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52608.
2021-11-25 16:34:55 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.3:52608
2021-11-25 16:34:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-11-25 16:34:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.3, 52608, None)
2021-11-25 16:34:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.3:52608 with 912.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 52608, None)
2021-11-25 16:34:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.3, 52608, None)
2021-11-25 16:34:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 52608, None)
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7b22ec89{/metrics/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/').
2021-11-25 16:34:56 INFO  SharedState:54 - Warehouse path is 'file:/Users/tusharmudgal/Desktop/ETLkafka/spark-warehouse/'.
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18fdb6cf{/SQL,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d02f8d{/SQL/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@720653c2{/SQL/execution,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f24169{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/static/sql,null,AVAILABLE,@Spark}
2021-11-25 16:34:56 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-11-25 16:34:59 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-11-25 16:34:59 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-11-25 16:34:59 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-11-25 16:34:59 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-11-25 16:35:00 INFO  CodeGenerator:54 - Code generated in 311.754875 ms
2021-11-25 16:35:00 INFO  CodeGenerator:54 - Code generated in 31.041166 ms
2021-11-25 16:35:00 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 251.1 KB, free 912.1 MB)
2021-11-25 16:35:00 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.5 KB, free 912.0 MB)
2021-11-25 16:35:00 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.3:52608 (size: 21.5 KB, free: 912.3 MB)
2021-11-25 16:35:00 INFO  SparkContext:54 - Created broadcast 0 from collectAsList at WriteToS3.scala:83
2021-11-25 16:35:00 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4197693 bytes, open cost is considered as scanning 4194304 bytes.
2021-11-25 16:35:00 INFO  SparkContext:54 - Starting job: collectAsList at WriteToS3.scala:83
2021-11-25 16:35:00 INFO  DAGScheduler:54 - Got job 0 (collectAsList at WriteToS3.scala:83) with 1 output partitions
2021-11-25 16:35:00 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (collectAsList at WriteToS3.scala:83)
2021-11-25 16:35:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-11-25 16:35:00 INFO  DAGScheduler:54 - Missing parents: List()
2021-11-25 16:35:00 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at collectAsList at WriteToS3.scala:83), which has no missing parents
2021-11-25 16:35:01 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 912.0 MB)
2021-11-25 16:35:01 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 912.0 MB)
2021-11-25 16:35:01 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.1.3:52608 (size: 5.3 KB, free: 912.3 MB)
2021-11-25 16:35:01 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2021-11-25 16:35:01 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collectAsList at WriteToS3.scala:83) (first 15 tasks are for partitions Vector(0))
2021-11-25 16:35:01 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2021-11-25 16:35:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
2021-11-25 16:35:01 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-11-25 16:35:01 INFO  CodeGenerator:54 - Code generated in 61.744834 ms
2021-11-25 16:35:01 INFO  FileScanRDD:54 - Reading File path: file:///Users/tusharmudgal/Desktop/ETLkafka/dynamic_schema/src/main/resources/test.txt, range: 0-3389, partition values: [empty row]
2021-11-25 16:35:01 INFO  CodeGenerator:54 - Code generated in 22.144792 ms
2021-11-25 16:35:01 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 2398 bytes result sent to driver
2021-11-25 16:35:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 377 ms on localhost (executor driver) (1/1)
2021-11-25 16:35:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-11-25 16:35:01 INFO  DAGScheduler:54 - ResultStage 0 (collectAsList at WriteToS3.scala:83) finished in 0.470 s
2021-11-25 16:35:01 INFO  DAGScheduler:54 - Job 0 finished: collectAsList at WriteToS3.scala:83, took 0.516273 s
2021-11-25 16:35:01 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-11-25 16:35:01 INFO  AbstractConnector:318 - Stopped Spark@4985cbcb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2021-11-25 16:35:01 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.1.3:4040
2021-11-25 16:35:01 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-11-25 16:35:01 INFO  MemoryStore:54 - MemoryStore cleared
2021-11-25 16:35:01 INFO  BlockManager:54 - BlockManager stopped
2021-11-25 16:35:01 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-11-25 16:35:01 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-11-25 16:35:01 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-11-25 16:35:01 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-11-25 16:35:01 INFO  ShutdownHookManager:54 - Deleting directory /private/var/folders/qm/xmg7pw6s0h33vfd60z2hf8sm0000gn/T/spark-481fd75d-03f6-4500-80fb-48bbf74f1566
